{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":95041,"databundleVersionId":11298874,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas numpy matplotlib tqdm torch torchvision scikit-learn albumentations Pillow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet50, alexnet, vgg16, googlenet\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import f1_score\nimport copy\nimport gc\nimport random\nfrom tqdm.auto import tqdm\n\n\n# Set random seeds for reproducibility\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nseed_everything(42)\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define paths with environment variable fallbacks for flexibility\nTRAIN_DIR = os.environ.get('TRAIN_DIR', '/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/train')\nTEST_DIR = os.environ.get('TEST_DIR', '/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/test')\nOUTPUT_DIR = os.environ.get('OUTPUT_DIR', './')\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nOUTPUT_FILE = os.path.join(OUTPUT_DIR, '21F3000611.csv')  # Replace with your roll number\nMODEL_DIR = os.path.join(OUTPUT_DIR, 'models')\nos.makedirs(MODEL_DIR, exist_ok=True)\n\n\n# Define image transformations with improved augmentations\ndef get_train_transforms(height=384, width=384):\n    return A.Compose([\n        A.RandomResizedCrop(height=height, width=width, scale=(0.7, 1.0)),\n        A.OneOf([\n            A.HorizontalFlip(p=0.8),\n            A.VerticalFlip(p=0.8),\n            A.RandomRotate90(p=0.8),\n        ], p=0.8),\n        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.8),\n        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.8),\n        A.OneOf([\n            A.GaussNoise(var_limit=(10.0, 80.0)),\n            A.GaussianBlur(blur_limit=(3, 7)),\n            A.MotionBlur(blur_limit=(3, 7)),\n        ], p=0.5),\n        A.OneOf([\n            A.GridDistortion(p=1.0),\n            A.ElasticTransform(p=1.0),\n            A.OpticalDistortion(p=1.0),\n        ], p=0.3),\n        A.CoarseDropout(max_holes=12, max_height=20, max_width=20, fill_value=0, p=0.5),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ])\n\n\ndef get_valid_transforms(height=384, width=384):\n    return A.Compose([\n        A.Resize(height=height, width=width),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ])\n\n\n# TTA transformations\ndef get_tta_transforms(height=384, width=384, n_transforms=7):\n    tta_transforms = []\n    # Original validation transform\n    tta_transforms.append(get_valid_transforms(height, width))\n\n    # Add more augmentations for TTA\n    tta_transforms.append(A.Compose([\n        A.Resize(height=height, width=width),\n        A.HorizontalFlip(p=1.0),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ]))\n\n    tta_transforms.append(A.Compose([\n        A.Resize(height=height, width=width),\n        A.VerticalFlip(p=1.0),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ]))\n\n    tta_transforms.append(A.Compose([\n        A.Resize(height=height, width=width),\n        A.RandomRotate90(p=1.0),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ]))\n\n    tta_transforms.append(A.Compose([\n        A.Resize(height=height, width=width),\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ]))\n\n    tta_transforms.append(A.Compose([\n        A.Resize(height=height, width=width),\n        A.Transpose(p=1.0),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ]))\n\n    tta_transforms.append(A.Compose([\n        A.Resize(height=height + 32, width=width + 32),\n        A.CenterCrop(height=height, width=width),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2(),\n    ]))\n\n    return tta_transforms[:n_transforms]\n\n\n# Custom Dataset with Albumentations support\nclass AlbumentationsDataset(Dataset):\n    def __init__(self, root_dir, transform=None, is_test=False):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.is_test = is_test\n\n        if not is_test:\n            # Training/validation mode\n            self.dataset = ImageFolder(root_dir)\n            self.classes = self.dataset.classes\n            self.class_to_idx = self.dataset.class_to_idx\n            self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n            self.samples = self.dataset.samples\n\n            # Count samples per class for reference\n            from collections import Counter\n            self.class_counts = Counter([label for _, label in self.samples])\n        else:\n            # Test mode\n            self.image_files = sorted(\n                [f for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n\n    def __len__(self):\n        if not self.is_test:\n            return len(self.samples)\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        if not self.is_test:\n            img_path, label = self.samples[idx]\n            image = Image.open(img_path).convert('RGB')\n            image = np.array(image)\n\n            if self.transform:\n                augmented = self.transform(image=image)\n                image = augmented['image']\n\n            return image, label\n        else:\n            img_path = os.path.join(self.root_dir, self.image_files[idx])\n            image = Image.open(img_path).convert('RGB')\n            image = np.array(image)\n            image_id = os.path.splitext(self.image_files[idx])[0]\n\n            if self.transform:\n                augmented = self.transform(image=image)\n                image = augmented['image']\n\n            return image, image_id\n\n\n# Create datasets\ntrain_dataset = AlbumentationsDataset(TRAIN_DIR, transform=get_train_transforms(384, 384))\ntest_dataset = AlbumentationsDataset(TEST_DIR, transform=get_valid_transforms(384, 384), is_test=True)\n\n\n# Define model creation functions\ndef create_model(model_name, num_classes=10, pretrained=True):\n    if model_name == 'resnet50':\n        model = resnet50(weights='DEFAULT' if pretrained else None)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n    elif model_name == 'alexnet':\n        model = alexnet(weights='DEFAULT' if pretrained else None)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n    elif model_name == 'vgg16':\n        model = vgg16(weights='DEFAULT' if pretrained else None)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n    elif model_name == 'googlenet':\n        model = googlenet(weights='DEFAULT' if pretrained else None)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n    else:\n        raise ValueError(f\"Unsupported model name: {model_name}\")\n    return model\n\n\n# Define model configurations - using all models as requested\nmodel_configs = [\n    # format: (model_name, learning_rate, weight_decay, batch_size)\n    ('resnet50', 1e-4, 1e-4, 32),\n    ('vgg16', 5e-5, 1e-4, 16),\n    ('alexnet', 2e-4, 1e-4, 64),\n    ('googlenet', 1e-4, 1e-4, 32),\n]\n\n\n# Early stopping class\nclass EarlyStopping:\n    def __init__(self, patience=7, delta=0, path='checkpoint.pt'):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_f1_max = -np.Inf\n        self.delta = delta\n        self.path = path\n        self.best_epoch = 0\n\n    def __call__(self, val_f1, model, epoch):\n        score = val_f1\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_f1, model)\n            self.best_epoch = epoch\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_f1, model)\n            self.counter = 0\n            self.best_epoch = epoch\n\n    def save_checkpoint(self, val_f1, model):\n        torch.save(model.state_dict(), self.path)\n        self.val_f1_max = val_f1\n\n\n# Training function with improvements\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n                model_name, num_epochs=25, mixup_alpha=0.2, clip_grad_norm=1.0,\n                early_stopping_patience=7):\n    # Early stopping\n    early_stopping = EarlyStopping(\n        patience=early_stopping_patience,\n        path=os.path.join(MODEL_DIR, f\"{model_name}_early_stop.pth\")\n    )\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_f1 = 0.0\n    best_epoch = 0\n\n    # Define mixup function\n    def mixup_data(x, y, alpha=0.2):\n        if alpha > 0:\n            lam = np.random.beta(alpha, alpha)\n        else:\n            lam = 1\n        batch_size = x.size()[0]\n        index = torch.randperm(batch_size).to(device)\n        mixed_x = lam * x + (1 - lam) * x[index, :]\n        y_a, y_b = y, y[index]\n        return mixed_x, y_a, y_b, lam\n\n    def mixup_criterion(criterion, pred, y_a, y_b, lam):\n        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n    # Enable automatic mixed precision\n    scaler = torch.cuda.amp.GradScaler()\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        processed_samples = 0\n        all_labels = []\n        all_preds = []\n\n        # Training loop\n        for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}'):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Zero the parameter gradients - moved here to ensure proper gradient reset\n            optimizer.zero_grad()\n\n            # Apply mixup with probability 0.5\n            use_mixup = random.random() < 0.5 and mixup_alpha > 0\n            if use_mixup:\n                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=mixup_alpha)\n\n                # Forward pass with AMP\n                with torch.cuda.amp.autocast():\n                    outputs = model(inputs)\n                    loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n\n                # For accuracy calculation during mixup, use the dominant label\n                with torch.no_grad():\n                    _, preds = torch.max(outputs, 1)\n                    # For F1 calculation, use dominant label\n                    dominant_labels = labels_a if lam > 0.5 else labels_b\n                    all_labels.extend(dominant_labels.cpu().numpy())\n                    all_preds.extend(preds.cpu().numpy())\n            else:\n                # Standard forward pass with AMP\n                with torch.cuda.amp.autocast():\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n\n                with torch.no_grad():\n                    _, preds = torch.max(outputs, 1)\n                    # Store labels and predictions for F1 calculation\n                    all_labels.extend(labels.cpu().numpy())\n                    all_preds.extend(preds.cpu().numpy())\n\n            # Backward pass with AMP\n            scaler.scale(loss).backward()\n\n            # Gradient clipping\n            if clip_grad_norm > 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n\n            # Optimize with AMP\n            scaler.step(optimizer)\n            scaler.update()\n\n            # Statistics\n            batch_size = inputs.size(0)\n            running_loss += loss.item() * batch_size\n            processed_samples += batch_size\n\n            # Calculate training metrics for the epoch\n            train_loss = running_loss / processed_samples\n            train_f1 = f1_score(all_labels, all_preds, average='weighted')\n\n            # Free memory after finishing training phase\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n            # Validation phase - moved outside the training batch loop\n            model.eval()\n            all_val_labels = []\n            all_val_preds = []\n            val_loss = 0.0\n            val_processed_samples = 0\n\n            with torch.no_grad():\n                for inputs, labels in tqdm(val_loader, desc=f'Validating Epoch {epoch + 1}/{num_epochs}'):\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    with torch.cuda.amp.autocast():\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n                    val_loss += loss.item() * inputs.size(0)\n                    val_processed_samples += inputs.size(0)\n\n                    # Store predictions and labels for F1 calculation\n                    all_val_labels.extend(labels.cpu().numpy())\n                    all_val_preds.extend(preds.cpu().numpy())\n\n            # Calculate validation metrics\n            val_loss /= val_processed_samples\n            epoch_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n\n            # Print epoch results\n            print(f'Epoch {epoch + 1}/{num_epochs}')\n            print(f'Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}')\n            print(f'Val Loss: {val_loss:.4f}, Val F1: {epoch_f1:.4f}')\n\n            # Update scheduler - fixed to handle all scheduler types properly\n            if scheduler is not None:\n                if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n                    scheduler.step(epoch_f1)\n                else:\n                    scheduler.step()\n\n            # Check early stopping - now passing the epoch number\n            early_stopping(epoch_f1, model, epoch)\n            if early_stopping.early_stop:\n                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n                break\n\n            # Save best model\n            if epoch_f1 > best_f1:\n                best_f1 = epoch_f1\n                best_model_wts = copy.deepcopy(model.state_dict())\n                best_epoch = epoch\n                # Save the model checkpoint\n                model_path = os.path.join(MODEL_DIR, f\"{model_name}_best.pth\")\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': best_model_wts,\n                    'f1': best_f1,\n                }, model_path)\n\n            # Clear memory after validation\n            del all_val_labels, all_val_preds\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n            # Clean up training phase variables\n            del all_labels, all_preds\n            gc.collect()\n\n        # Load the best model weights\n        print(f\"Loading best model from epoch {early_stopping.best_epoch if early_stopping.early_stop else best_epoch}\")\n        if early_stopping.early_stop:\n            model.load_state_dict(torch.load(early_stopping.path))\n            return model, early_stopping.val_f1_max\n        else:\n            model.load_state_dict(best_model_wts)\n            return model, best_f1\n\n\n# Training function with holdout validation\ndef train_models_holdout(model_configs, val_split=0.2, num_epochs=25):\n    # Create a validation split\n    train_size = int((1 - val_split) * len(train_dataset))\n    val_size = len(train_dataset) - train_size\n    temp_train_dataset, temp_val_dataset = random_split(\n        train_dataset, [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n\n    model_results = []\n\n    for model_name, lr, weight_decay, batch_size in model_configs:\n        print(f\"\\nTraining {model_name} model\")\n        # Create data loaders with optimal worker count\n        num_workers = min(os.cpu_count() or 1, 4)  # Adaptive worker count\n\n        train_loader = DataLoader(\n            temp_train_dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True,\n            persistent_workers=True if num_workers > 0 else False\n        )\n\n        val_loader = DataLoader(\n            temp_val_dataset,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True,\n            persistent_workers=True if num_workers > 0 else False\n        )\n\n        # Create model with exception handling\n        try:\n            model = create_model(model_name, num_classes=len(train_dataset.classes), pretrained=True)\n            model = model.to(device)\n\n            # Define loss function with label smoothing\n            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n            # Define optimizer\n            optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n            # Define OneCycleLR scheduler\n            steps_per_epoch = len(train_loader)\n            scheduler = optim.lr_scheduler.OneCycleLR(\n                optimizer,\n                max_lr=lr * 10,\n                steps_per_epoch=steps_per_epoch,\n                epochs=num_epochs,\n                pct_start=0.3,  # Warm up for 30% of training\n                div_factor=10,  # Initial LR is max_lr/div_factor\n                final_div_factor=100  # Min LR is max_lr/(div_factor*final_div_factor)\n            )\n\n            # Train model with early stopping and gradient clipping\n            model, best_f1 = train_model(\n                model=model,\n                train_loader=train_loader,\n                val_loader=val_loader,\n                criterion=criterion,\n                optimizer=optimizer,\n                scheduler=scheduler,\n                model_name=model_name,\n                num_epochs=num_epochs,\n                mixup_alpha=0.2,\n                clip_grad_norm=1.0,\n                early_stopping_patience=7\n            )\n\n            print(f\"{model_name} finished training with best F1: {best_f1:.4f}\")\n            # Store model and F1 score\n            model_results.append((model_name, model, best_f1))\n\n        except Exception as e:\n            print(f\"Error training {model_name}: {str(e)}\")\n            continue\n        finally:\n            # Free up memory\n            del train_loader, val_loader, optimizer, scheduler\n            gc.collect()\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n    return model_results\n\n\n# Generate features for meta-model training using TTA (consistent with test data)\ndef generate_meta_features(models, dataset, is_test=False, n_transforms=3):\n    all_ids = []\n    all_probs = []\n\n    # For each sample in the dataset\n    for i, (model_name, model, _) in enumerate(models):\n        model.eval()\n\n        # Create TTA transforms - use fewer transforms for validation to save time\n        tta_transforms = get_tta_transforms(n_transforms=n_transforms)\n        model_probs = []\n\n        # For the first model, get IDs\n        if i == 0:\n            test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n            for data in test_loader:\n                if not is_test:\n                    _, label = data\n                    all_ids.extend(label.numpy())\n                else:\n                    _, image_id = data\n                    all_ids.extend(image_id)\n\n        # For each TTA transform\n        for transform_idx, transform in enumerate(tta_transforms):\n            # Create a dataset with this transform\n            if not is_test:\n                # Create a custom dataset with the transform\n                transformed_dataset = AlbumentationsDataset(\n                    dataset.dataset.root_dir,\n                    transform=transform\n                )\n                # Keep only the validation indices\n                indices = dataset.indices\n                from torch.utils.data import Subset\n                transformed_dataset = Subset(transformed_dataset, indices)\n            else:\n                transformed_dataset = AlbumentationsDataset(\n                    TEST_DIR,\n                    transform=transform,\n                    is_test=True\n                )\n\n            # Create a loader\n            loader = DataLoader(\n                transformed_dataset,\n                batch_size=32,\n                shuffle=False,\n                num_workers=min(os.cpu_count() or 1, 4),\n                pin_memory=True\n            )\n\n            # Collect predictions for this transform\n            transform_probs = []\n\n            with torch.cuda.amp.autocast(enabled=True):\n                with torch.no_grad():\n                    for batch in tqdm(loader,\n                                      desc=f\"Model {model_name}, TTA {transform_idx + 1}/{len(tta_transforms)}\"):\n                        if not is_test:\n                            inputs, _ = batch\n                        else:\n                            inputs, _ = batch\n\n                        inputs = inputs.to(device)\n                        outputs = model(inputs)\n                        probs = torch.softmax(outputs, dim=1)\n                        transform_probs.append(probs.cpu().numpy())\n\n            # Concatenate all batches for this transform\n            transform_probs = np.vstack(transform_probs)\n            model_probs.append(transform_probs)\n\n            # Free memory\n            del transformed_dataset, loader, transform_probs\n            gc.collect()\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n        # Average predictions across TTA transforms\n        avg_probs = np.mean(model_probs, axis=0)\n        all_probs.append(avg_probs)\n\n        # Free memory for this model\n        del model_probs\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    # Stack features from all models\n    stacked_features = np.hstack(all_probs)\n\n    return stacked_features, all_ids\n\n\n# Improved stacking ensemble prediction function\ndef stacking_ensemble_predict(model_results, test_dataset):\n    # Create validation dataset for training the meta-model\n    # Uses a different split than the base models to prevent data leakage\n    val_dataset = AlbumentationsDataset(TRAIN_DIR, transform=get_valid_transforms(384, 384))\n    train_size = int(0.7 * len(val_dataset))  # Use 70% for training base models\n    val_size = len(val_dataset) - train_size  # Use 30% for training meta-model\n\n    # Use a different seed than for base model training to get a different split\n    _, meta_train_dataset = random_split(\n        val_dataset, [train_size, val_size],\n        generator=torch.Generator().manual_seed(43)  # Different seed\n    )\n\n    # Generate features for meta-model training using TTA for consistency\n    print(\"Generating features for meta-model training using TTA...\")\n    X_train, y_train = generate_meta_features(model_results, meta_train_dataset, n_transforms=3)\n\n    # Apply feature scaling\n    print(\"Scaling features...\")\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n\n    # Train the meta-model (Random Forest with tuned parameters)\n    print(\"Training meta-model...\")\n    meta_model = RandomForestClassifier(\n        n_estimators=200,\n        max_depth=None,\n        min_samples_split=2,\n        random_state=42,\n        class_weight='balanced',  # Added to handle class imbalance\n        n_jobs=-1\n    )\n    meta_model.fit(X_train_scaled, y_train)\n\n    # Generate features for test data using TTA\n    print(\"Generating test features using TTA...\")\n    X_test, test_ids = generate_meta_features(model_results, test_dataset, is_test=True, n_transforms=7)\n\n    # Scale the test features using the same scaler\n    X_test_scaled = scaler.transform(X_test)\n\n    # Make predictions with the meta-model\n    print(\"Making final predictions...\")\n    predicted_classes = meta_model.predict(X_test_scaled)\n\n    # Create a dataframe with results\n    results = pd.DataFrame({\n        'image_id': test_ids,\n        'class_id': predicted_classes,\n    })\n\n    # Convert numeric class_id to original class name\n    results['class_name'] = results['class_id'].apply(lambda x: train_dataset.idx_to_class[x])\n\n    # Sort by image_id for consistent order\n    results = results.sort_values('image_id')\n\n    return results\n\n\n# Add an error handling wrapper to the main function\ndef with_error_handling(func):\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:\n            import traceback\n            print(f\"Error: {str(e)}\")\n            print(traceback.format_exc())\n            # Try to release GPU memory in case of error\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            raise\n\n    return wrapper\n\n\n# Main training pipeline with better error handling\n@with_error_handling\ndef main():\n    print(\"Starting training pipeline...\")\n    print(f\"Using device: {device}\")\n    print(f\"Train dataset contains {len(train_dataset)} images\")\n    print(f\"Test dataset contains {len(test_dataset)} images\")\n\n    # Train models with holdout validation and longer training\n    model_results = train_models_holdout(\n        model_configs=model_configs,\n        val_split=0.2,\n        num_epochs=25\n    )\n\n    if not model_results:\n        raise ValueError(\"No models were successfully trained\")\n\n    # Make predictions using stacking ensemble\n    print(\"Making ensemble predictions...\")\n    results = stacking_ensemble_predict(\n        model_results=model_results,\n        test_dataset=test_dataset\n    )\n\n    # Generate submission file\n    print(\"Generating submission file...\")\n    submission = results[['image_id', 'class_name']]\n    submission.columns = ['image_id', 'label']\n\n    # Define the mapping of labels to numeric values\n    label_map = {\n        \"Amphibia\": 0,\n        \"Animalia\": 1,\n        \"Arachnida\": 2,\n        \"Aves\": 3,\n        \"Fungi\": 4,\n        \"Insecta\": 5,\n        \"Mammalia\": 6,\n        \"Mollusca\": 7,\n        \"Plantae\": 8,\n        \"Reptilia\": 9\n    }\n\n    # Map the string labels to numeric labels\n    submission['label'] = submission['label'].map(label_map)\n\n    # Verify there are no NaN values\n    if submission.isnull().sum().sum() > 0:\n        print(\"Warning: NaN values detected in submission file\")\n        # Fill missing values with most common class (fallback)\n        most_common_class = submission['label'].mode()[0]\n        submission['label'] = submission['label'].fillna(most_common_class)\n\n    # Save the result to a new CSV file\n    submission.to_csv(OUTPUT_FILE, index=False)\n    print(f\"Submission saved to {OUTPUT_FILE}\")\n\n    return results\n    \n    except Exception as e:\n        print(f\"Error in main function: {str(e)}\")\n        raise\n\n# Execute main function\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}