{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941733b2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-14T11:23:34.139456Z",
     "iopub.status.busy": "2025-03-14T11:23:34.139026Z",
     "iopub.status.idle": "2025-03-14T11:23:40.462963Z",
     "shell.execute_reply": "2025-03-14T11:23:40.461589Z"
    },
    "papermill": {
     "duration": 6.33021,
     "end_time": "2025-03-14T11:23:40.465155",
     "exception": false,
     "start_time": "2025-03-14T11:23:34.134945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.11.0a2)\r\n",
      "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\r\n",
      "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.11.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.29.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib tqdm torch torchvision scikit-learn albumentations Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0817d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:23:40.474359Z",
     "iopub.status.busy": "2025-03-14T11:23:40.473985Z",
     "iopub.status.idle": "2025-03-14T11:24:08.843598Z",
     "shell.execute_reply": "2025-03-14T11:24:08.842507Z"
    },
    "papermill": {
     "duration": 28.376789,
     "end_time": "2025-03-14T11:24:08.845636",
     "exception": false,
     "start_time": "2025-03-14T11:23:40.468847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, alexnet, vgg16, googlenet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import f1_score\n",
    "import copy\n",
    "import gc\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define paths with environment variable fallbacks for flexibility\n",
    "TRAIN_DIR = os.environ.get('TRAIN_DIR', '/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/train')\n",
    "TEST_DIR = os.environ.get('TEST_DIR', '/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/test')\n",
    "OUTPUT_DIR = os.environ.get('OUTPUT_DIR', './')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, '21F3000611.csv')  # Replace with your roll number\n",
    "MODEL_DIR = os.path.join(OUTPUT_DIR, 'models')\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define image transformations with improved augmentations\n",
    "def get_train_transforms(height=384, width=384):\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(height=height, width=width, scale=(0.7, 1.0)),\n",
    "        A.OneOf([\n",
    "            A.HorizontalFlip(p=0.8),\n",
    "            A.VerticalFlip(p=0.8),\n",
    "            A.RandomRotate90(p=0.8),\n",
    "        ], p=0.8),\n",
    "        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.8),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.8),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10.0, 80.0)),\n",
    "            A.GaussianBlur(blur_limit=(3, 7)),\n",
    "            A.MotionBlur(blur_limit=(3, 7)),\n",
    "        ], p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GridDistortion(p=1.0),\n",
    "            A.ElasticTransform(p=1.0),\n",
    "            A.OpticalDistortion(p=1.0),\n",
    "        ], p=0.3),\n",
    "        A.CoarseDropout(max_holes=12, max_height=20, max_width=20, fill_value=0, p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(height=384, width=384):\n",
    "    return A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "# TTA transformations\n",
    "def get_tta_transforms(height=384, width=384, n_transforms=7):\n",
    "    tta_transforms = []\n",
    "    # Original validation transform\n",
    "    tta_transforms.append(get_valid_transforms(height, width))\n",
    "\n",
    "    # Add more augmentations for TTA\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=height, width=width),\n",
    "        A.Transpose(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "\n",
    "    tta_transforms.append(A.Compose([\n",
    "        A.Resize(height=height + 32, width=width + 32),\n",
    "        A.CenterCrop(height=height, width=width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "\n",
    "    return tta_transforms[:n_transforms]\n",
    "\n",
    "\n",
    "# Custom Dataset with Albumentations support\n",
    "class AlbumentationsDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "        if not is_test:\n",
    "            # Training/validation mode\n",
    "            self.dataset = ImageFolder(root_dir)\n",
    "            self.classes = self.dataset.classes\n",
    "            self.class_to_idx = self.dataset.class_to_idx\n",
    "            self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "            self.samples = self.dataset.samples\n",
    "\n",
    "            # Count samples per class for reference\n",
    "            from collections import Counter\n",
    "            self.class_counts = Counter([label for _, label in self.samples])\n",
    "        else:\n",
    "            # Test mode\n",
    "            self.image_files = sorted(\n",
    "                [f for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.is_test:\n",
    "            return len(self.samples)\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = np.array(image)\n",
    "\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "\n",
    "            return image, label\n",
    "        else:\n",
    "            img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = np.array(image)\n",
    "            image_id = os.path.splitext(self.image_files[idx])[0]\n",
    "\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "\n",
    "            return image, image_id\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AlbumentationsDataset(TRAIN_DIR, transform=get_train_transforms(384, 384))\n",
    "test_dataset = AlbumentationsDataset(TEST_DIR, transform=get_valid_transforms(384, 384), is_test=True)\n",
    "\n",
    "\n",
    "# Define model creation functions\n",
    "def create_model(model_name, num_classes=10, pretrained=True):\n",
    "    if model_name == 'resnet50':\n",
    "        model = resnet50(weights='DEFAULT' if pretrained else None)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    elif model_name == 'alexnet':\n",
    "        model = alexnet(weights='DEFAULT' if pretrained else None)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    elif model_name == 'vgg16':\n",
    "        model = vgg16(weights='DEFAULT' if pretrained else None)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    elif model_name == 'googlenet':\n",
    "        model = googlenet(weights='DEFAULT' if pretrained else None)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define model configurations - using all models as requested\n",
    "model_configs = [\n",
    "    # format: (model_name, learning_rate, weight_decay, batch_size)\n",
    "    ('resnet50', 1e-4, 1e-4, 32),\n",
    "    ('vgg16', 5e-5, 1e-4, 16),\n",
    "    ('alexnet', 2e-4, 1e-4, 64),\n",
    "    ('googlenet', 1e-4, 1e-4, 32),\n",
    "]\n",
    "\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_f1_max = -np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def __call__(self, val_f1, model, epoch):\n",
    "        score = val_f1\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "            self.best_epoch = epoch\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "            self.counter = 0\n",
    "            self.best_epoch = epoch\n",
    "\n",
    "    def save_checkpoint(self, val_f1, model):\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_f1_max = val_f1\n",
    "\n",
    "\n",
    "# Training function with improvements\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                model_name, num_epochs=25, mixup_alpha=0.2, clip_grad_norm=1.0,\n",
    "                early_stopping_patience=7):\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=early_stopping_patience,\n",
    "        path=os.path.join(MODEL_DIR, f\"{model_name}_early_stop.pth\")\n",
    "    )\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    # Define mixup function\n",
    "    def mixup_data(x, y, alpha=0.2):\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "        batch_size = x.size()[0]\n",
    "        index = torch.randperm(batch_size).to(device)\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "    def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "    # Enable automatic mixed precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        processed_samples = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients - moved here to ensure proper gradient reset\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Apply mixup with probability 0.5\n",
    "            use_mixup = random.random() < 0.5 and mixup_alpha > 0\n",
    "            if use_mixup:\n",
    "                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=mixup_alpha)\n",
    "\n",
    "                # Forward pass with AMP\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "\n",
    "                # For accuracy calculation during mixup, use the dominant label\n",
    "                with torch.no_grad():\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # For F1 calculation, use dominant label\n",
    "                    dominant_labels = labels_a if lam > 0.5 else labels_b\n",
    "                    all_labels.extend(dominant_labels.cpu().numpy())\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "            else:\n",
    "                # Standard forward pass with AMP\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # Store labels and predictions for F1 calculation\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            # Backward pass with AMP\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            if clip_grad_norm > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "\n",
    "            # Optimize with AMP\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Statistics\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            processed_samples += batch_size\n",
    "\n",
    "            # Calculate training metrics for the epoch\n",
    "            train_loss = running_loss / processed_samples\n",
    "            train_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "            # Free memory after finishing training phase\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Validation phase - moved outside the training batch loop\n",
    "            model.eval()\n",
    "            all_val_labels = []\n",
    "            all_val_preds = []\n",
    "            val_loss = 0.0\n",
    "            val_processed_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in tqdm(val_loader, desc=f'Validating Epoch {epoch + 1}/{num_epochs}'):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    val_loss += loss.item() * inputs.size(0)\n",
    "                    val_processed_samples += inputs.size(0)\n",
    "\n",
    "                    # Store predictions and labels for F1 calculation\n",
    "                    all_val_labels.extend(labels.cpu().numpy())\n",
    "                    all_val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_loss /= val_processed_samples\n",
    "            epoch_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "\n",
    "            # Print epoch results\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val F1: {epoch_f1:.4f}')\n",
    "\n",
    "            # Update scheduler - fixed to handle all scheduler types properly\n",
    "            if scheduler is not None:\n",
    "                if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(epoch_f1)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "            # Check early stopping - now passing the epoch number\n",
    "            early_stopping(epoch_f1, model, epoch)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "            # Save best model\n",
    "            if epoch_f1 > best_f1:\n",
    "                best_f1 = epoch_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "                # Save the model checkpoint\n",
    "                model_path = os.path.join(MODEL_DIR, f\"{model_name}_best.pth\")\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': best_model_wts,\n",
    "                    'f1': best_f1,\n",
    "                }, model_path)\n",
    "\n",
    "            # Clear memory after validation\n",
    "            del all_val_labels, all_val_preds\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Clean up training phase variables\n",
    "            del all_labels, all_preds\n",
    "            gc.collect()\n",
    "\n",
    "        # Load the best model weights\n",
    "        print(f\"Loading best model from epoch {early_stopping.best_epoch if early_stopping.early_stop else best_epoch}\")\n",
    "        if early_stopping.early_stop:\n",
    "            model.load_state_dict(torch.load(early_stopping.path))\n",
    "            return model, early_stopping.val_f1_max\n",
    "        else:\n",
    "            model.load_state_dict(best_model_wts)\n",
    "            return model, best_f1\n",
    "\n",
    "\n",
    "# Training function with holdout validation\n",
    "def train_models_holdout(model_configs, val_split=0.2, num_epochs=25):\n",
    "    # Create a validation split\n",
    "    train_size = int((1 - val_split) * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    temp_train_dataset, temp_val_dataset = random_split(\n",
    "        train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "\n",
    "    model_results = []\n",
    "\n",
    "    for model_name, lr, weight_decay, batch_size in model_configs:\n",
    "        print(f\"\\nTraining {model_name} model\")\n",
    "        # Create data loaders with optimal worker count\n",
    "        num_workers = min(os.cpu_count() or 1, 4)  # Adaptive worker count\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            temp_train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if num_workers > 0 else False\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            temp_val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if num_workers > 0 else False\n",
    "        )\n",
    "\n",
    "        # Create model with exception handling\n",
    "        try:\n",
    "            model = create_model(model_name, num_classes=len(train_dataset.classes), pretrained=True)\n",
    "            model = model.to(device)\n",
    "\n",
    "            # Define loss function with label smoothing\n",
    "            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "            # Define optimizer\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "            # Define OneCycleLR scheduler\n",
    "            steps_per_epoch = len(train_loader)\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=lr * 10,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=num_epochs,\n",
    "                pct_start=0.3,  # Warm up for 30% of training\n",
    "                div_factor=10,  # Initial LR is max_lr/div_factor\n",
    "                final_div_factor=100  # Min LR is max_lr/(div_factor*final_div_factor)\n",
    "            )\n",
    "\n",
    "            # Train model with early stopping and gradient clipping\n",
    "            model, best_f1 = train_model(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                model_name=model_name,\n",
    "                num_epochs=num_epochs,\n",
    "                mixup_alpha=0.2,\n",
    "                clip_grad_norm=1.0,\n",
    "                early_stopping_patience=7\n",
    "            )\n",
    "\n",
    "            print(f\"{model_name} finished training with best F1: {best_f1:.4f}\")\n",
    "            # Store model and F1 score\n",
    "            model_results.append((model_name, model, best_f1))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name}: {str(e)}\")\n",
    "            continue\n",
    "        finally:\n",
    "            # Free up memory\n",
    "            del train_loader, val_loader, optimizer, scheduler\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    return model_results\n",
    "\n",
    "\n",
    "# Generate features for meta-model training using TTA (consistent with test data)\n",
    "def generate_meta_features(models, dataset, is_test=False, n_transforms=3):\n",
    "    all_ids = []\n",
    "    all_probs = []\n",
    "\n",
    "    # For each sample in the dataset\n",
    "    for i, (model_name, model, _) in enumerate(models):\n",
    "        model.eval()\n",
    "\n",
    "        # Create TTA transforms - use fewer transforms for validation to save time\n",
    "        tta_transforms = get_tta_transforms(n_transforms=n_transforms)\n",
    "        model_probs = []\n",
    "\n",
    "        # For the first model, get IDs\n",
    "        if i == 0:\n",
    "            test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "            for data in test_loader:\n",
    "                if not is_test:\n",
    "                    _, label = data\n",
    "                    all_ids.extend(label.numpy())\n",
    "                else:\n",
    "                    _, image_id = data\n",
    "                    all_ids.extend(image_id)\n",
    "\n",
    "        # For each TTA transform\n",
    "        for transform_idx, transform in enumerate(tta_transforms):\n",
    "            # Create a dataset with this transform\n",
    "            if not is_test:\n",
    "                # Create a custom dataset with the transform\n",
    "                transformed_dataset = AlbumentationsDataset(\n",
    "                    dataset.dataset.root_dir,\n",
    "                    transform=transform\n",
    "                )\n",
    "                # Keep only the validation indices\n",
    "                indices = dataset.indices\n",
    "                from torch.utils.data import Subset\n",
    "                transformed_dataset = Subset(transformed_dataset, indices)\n",
    "            else:\n",
    "                transformed_dataset = AlbumentationsDataset(\n",
    "                    TEST_DIR,\n",
    "                    transform=transform,\n",
    "                    is_test=True\n",
    "                )\n",
    "\n",
    "            # Create a loader\n",
    "            loader = DataLoader(\n",
    "                transformed_dataset,\n",
    "                batch_size=32,\n",
    "                shuffle=False,\n",
    "                num_workers=min(os.cpu_count() or 1, 4),\n",
    "                pin_memory=True\n",
    "            )\n",
    "\n",
    "            # Collect predictions for this transform\n",
    "            transform_probs = []\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                with torch.no_grad():\n",
    "                    for batch in tqdm(loader,\n",
    "                                      desc=f\"Model {model_name}, TTA {transform_idx + 1}/{len(tta_transforms)}\"):\n",
    "                        if not is_test:\n",
    "                            inputs, _ = batch\n",
    "                        else:\n",
    "                            inputs, _ = batch\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        outputs = model(inputs)\n",
    "                        probs = torch.softmax(outputs, dim=1)\n",
    "                        transform_probs.append(probs.cpu().numpy())\n",
    "\n",
    "            # Concatenate all batches for this transform\n",
    "            transform_probs = np.vstack(transform_probs)\n",
    "            model_probs.append(transform_probs)\n",
    "\n",
    "            # Free memory\n",
    "            del transformed_dataset, loader, transform_probs\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # Average predictions across TTA transforms\n",
    "        avg_probs = np.mean(model_probs, axis=0)\n",
    "        all_probs.append(avg_probs)\n",
    "\n",
    "        # Free memory for this model\n",
    "        del model_probs\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Stack features from all models\n",
    "    stacked_features = np.hstack(all_probs)\n",
    "\n",
    "    return stacked_features, all_ids\n",
    "\n",
    "\n",
    "# Improved stacking ensemble prediction function\n",
    "def stacking_ensemble_predict(model_results, test_dataset):\n",
    "    # Create validation dataset for training the meta-model\n",
    "    # Uses a different split than the base models to prevent data leakage\n",
    "    val_dataset = AlbumentationsDataset(TRAIN_DIR, transform=get_valid_transforms(384, 384))\n",
    "    train_size = int(0.7 * len(val_dataset))  # Use 70% for training base models\n",
    "    val_size = len(val_dataset) - train_size  # Use 30% for training meta-model\n",
    "\n",
    "    # Use a different seed than for base model training to get a different split\n",
    "    _, meta_train_dataset = random_split(\n",
    "        val_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(43)  # Different seed\n",
    "    )\n",
    "\n",
    "    # Generate features for meta-model training using TTA for consistency\n",
    "    print(\"Generating features for meta-model training using TTA...\")\n",
    "    X_train, y_train = generate_meta_features(model_results, meta_train_dataset, n_transforms=3)\n",
    "\n",
    "    # Apply feature scaling\n",
    "    print(\"Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Train the meta-model (Random Forest with tuned parameters)\n",
    "    print(\"Training meta-model...\")\n",
    "    meta_model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',  # Added to handle class imbalance\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    meta_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Generate features for test data using TTA\n",
    "    print(\"Generating test features using TTA...\")\n",
    "    X_test, test_ids = generate_meta_features(model_results, test_dataset, is_test=True, n_transforms=7)\n",
    "\n",
    "    # Scale the test features using the same scaler\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Make predictions with the meta-model\n",
    "    print(\"Making final predictions...\")\n",
    "    predicted_classes = meta_model.predict(X_test_scaled)\n",
    "\n",
    "    # Create a dataframe with results\n",
    "    results = pd.DataFrame({\n",
    "        'image_id': test_ids,\n",
    "        'class_id': predicted_classes,\n",
    "    })\n",
    "\n",
    "    # Convert numeric class_id to original class name\n",
    "    results['class_name'] = results['class_id'].apply(lambda x: train_dataset.idx_to_class[x])\n",
    "\n",
    "    # Sort by image_id for consistent order\n",
    "    results = results.sort_values('image_id')\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Add an error handling wrapper to the main function\n",
    "def with_error_handling(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            print(traceback.format_exc())\n",
    "            # Try to release GPU memory in case of error\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            raise\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# Main training pipeline with better error handling\n",
    "@with_error_handling\n",
    "def main():\n",
    "    print(\"Starting training pipeline...\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Train dataset contains {len(train_dataset)} images\")\n",
    "    print(f\"Test dataset contains {len(test_dataset)} images\")\n",
    "\n",
    "    # Train models with holdout validation and longer training\n",
    "    model_results = train_models_holdout(\n",
    "        model_configs=model_configs,\n",
    "        val_split=0.2,\n",
    "        num_epochs=25\n",
    "    )\n",
    "\n",
    "    if not model_results:\n",
    "        raise ValueError(\"No models were successfully trained\")\n",
    "\n",
    "    # Make predictions using stacking ensemble\n",
    "    print(\"Making ensemble predictions...\")\n",
    "    results = stacking_ensemble_predict(\n",
    "        model_results=model_results,\n",
    "        test_dataset=test_dataset\n",
    "    )\n",
    "\n",
    "    # Generate submission file\n",
    "    print(\"Generating submission file...\")\n",
    "    submission = results[['image_id', 'class_name']]\n",
    "    submission.columns = ['image_id', 'label']\n",
    "\n",
    "    # Define the mapping of labels to numeric values\n",
    "    label_map = {\n",
    "        \"Amphibia\": 0,\n",
    "        \"Animalia\": 1,\n",
    "        \"Arachnida\": 2,\n",
    "        \"Aves\": 3,\n",
    "        \"Fungi\": 4,\n",
    "        \"Insecta\": 5,\n",
    "        \"Mammalia\": 6,\n",
    "        \"Mollusca\": 7,\n",
    "        \"Plantae\": 8,\n",
    "        \"Reptilia\": 9\n",
    "    }\n",
    "\n",
    "    # Map the string labels to numeric labels\n",
    "    submission['label'] = submission['label'].map(label_map)\n",
    "\n",
    "    # Verify there are no NaN values\n",
    "    if submission.isnull().sum().sum() > 0:\n",
    "        print(\"Warning: NaN values detected in submission file\")\n",
    "        # Fill missing values with most common class (fallback)\n",
    "        most_common_class = submission['label'].mode()[0]\n",
    "        submission['label'] = submission['label'].fillna(most_common_class)\n",
    "\n",
    "    # Save the result to a new CSV file\n",
    "    submission.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"Submission saved to {OUTPUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11298874,
     "sourceId": 95041,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.61534,
   "end_time": "2025-03-14T11:24:11.769807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-14T11:23:31.154467",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
