{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3e13a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:50:35.593116Z",
     "iopub.status.busy": "2025-03-30T03:50:35.592829Z",
     "iopub.status.idle": "2025-03-30T03:50:40.846337Z",
     "shell.execute_reply": "2025-03-30T03:50:40.845248Z"
    },
    "papermill": {
     "duration": 5.257686,
     "end_time": "2025-03-30T03:50:40.847996",
     "exception": false,
     "start_time": "2025-03-30T03:50:35.590310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\r\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\r\n",
      "Collecting pytorch-msssim\r\n",
      "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\r\n",
      "Collecting torch_optimizer\r\n",
      "  Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.11.0a2)\r\n",
      "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\r\n",
      "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.11.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\r\n",
      "Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)\r\n",
      "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.29.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\r\n",
      "Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\r\n",
      "Installing collected packages: pytorch-ranger, pytorch-msssim, torch_optimizer\r\n",
      "Successfully installed pytorch-msssim-1.0.0 pytorch-ranger-0.1.1 torch_optimizer-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib scikit-learn pillow tqdm torch torchvision opencv-contrib-python albumentations pytorch-msssim transformers torch_optimizer pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b151f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T03:50:40.854131Z",
     "iopub.status.busy": "2025-03-30T03:50:40.853841Z",
     "iopub.status.idle": "2025-03-30T07:42:06.990242Z",
     "shell.execute_reply": "2025-03-30T07:42:06.989064Z"
    },
    "papermill": {
     "duration": 13886.141197,
     "end_time": "2025-03-30T07:42:06.991936",
     "exception": false,
     "start_time": "2025-03-30T03:50:40.850739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Epoch 1 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 1 Training: 100%|██████████| 418/418 [07:45<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 0.2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 2 Training: 100%|██████████| 418/418 [07:40<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Training Loss: 0.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 3 Training: 100%|██████████| 418/418 [07:39<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Training Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 4 Training: 100%|██████████| 418/418 [07:39<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Training Loss: 0.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 5 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Training Loss: 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 6 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Training Loss: 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 7 Training: 100%|██████████| 418/418 [07:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Training Loss: 0.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 8 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Training Loss: 0.1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 9 Training: 100%|██████████| 418/418 [07:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Training Loss: 0.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 10 Training: 100%|██████████| 418/418 [07:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Training Loss: 0.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 11 Training: 100%|██████████| 418/418 [07:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Training Loss: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 12 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Training Loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 13 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Training Loss: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 14 Training: 100%|██████████| 418/418 [07:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Training Loss: 0.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 15 Training: 100%|██████████| 418/418 [07:37<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Training Loss: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 16 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Training Loss: 0.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 17 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Training Loss: 0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 18 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Training Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 19 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Training Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 20 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Training Loss: 0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 21 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Training Loss: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 22 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Training Loss: 0.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 23 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Training Loss: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 24 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Training Loss: 0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 25 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Training Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 26 Training: 100%|██████████| 418/418 [07:36<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Training Loss: 0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 27 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Training Loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 28 Training: 100%|██████████| 418/418 [07:37<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Training Loss: 0.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 29 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Training Loss: 0.0701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training:   0%|          | 0/418 [00:00<?, ?it/s]<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "<ipython-input-2-64c342c2f64f>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  depth = torch.tensor(depth, dtype=torch.float32)\n",
      "Epoch 30 Training: 100%|██████████| 418/418 [07:38<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Training Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 53/53 [00:23<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from pytorch_msssim import SSIM\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# ------------------- Reproducibility -------------------\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "\n",
    "# ------------------- Configuration -------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 30\n",
    "BASE_LR = 2e-5  # Lower learning rate\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 4\n",
    "USE_AMP = False  # Disable mixed precision\n",
    "CLIP_VALUE = 1.0  # Gradient clipping value\n",
    "\n",
    "# ------------------- Data Augmentations -------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={\"mask\": \"mask\"})\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={\"mask\": \"mask\"})\n",
    "\n",
    "\n",
    "# ------------------- Dataset -------------------\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, rgb_dir: str, depth_dir: Optional[str] = None, transform: Optional[A.Compose] = None):\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.transform = transform\n",
    "        self.filenames = sorted(os.listdir(rgb_dir), key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        fname = self.filenames[idx]\n",
    "        rgb_path = os.path.join(self.rgb_dir, fname)\n",
    "        image = cv2.cvtColor(cv2.imread(rgb_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        depth = None\n",
    "        if self.depth_dir:\n",
    "            depth_path = os.path.join(self.depth_dir, fname)\n",
    "            depth = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "            depth = cv2.resize(depth, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            min_depth, max_depth = np.min(depth), np.max(depth)\n",
    "            depth = (depth - min_depth) / (max_depth - min_depth + 1e-8)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=depth if depth is not None else image)\n",
    "            image = augmented[\"image\"]\n",
    "            if depth is not None:\n",
    "                depth = augmented[\"mask\"].unsqueeze(0)\n",
    "        if depth is not None:\n",
    "            depth = torch.tensor(depth, dtype=torch.float32)\n",
    "        return (image, depth) if depth is not None else (image, fname)\n",
    "\n",
    "\n",
    "# ------------------- Modified UNet with Dilated Convolutions, Transposed Upsampling, and Refinement Module -------------------\n",
    "class ModifiedUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Standard convolution block (two conv layers)\n",
    "        def conv_block(in_channels: int, out_channels: int) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        # Convolution block with dilation in the second convolution\n",
    "        def conv_block_dilated(in_channels: int, out_channels: int) -> nn.Sequential:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=2, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = conv_block(3, 64)             # Output: 64 channels\n",
    "        self.encoder2 = conv_block(64, 128)           # Output: 128 channels\n",
    "        self.encoder3 = conv_block(128, 256)          # Output: 256 channels\n",
    "        self.encoder4 = conv_block(256, 512)          # Output: 512 channels\n",
    "        # Use dilated convolutions in the deepest layer\n",
    "        self.encoder5 = conv_block_dilated(512, 1024)   # Output: 1024 channels\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Transposed convolutions for upsampling\n",
    "        self.up5 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder (concatenating skip connections)\n",
    "        self.decoder5 = conv_block(512 + 512, 512)  # up5(e5) (512) + e4 (512) -> 1024 channels\n",
    "        self.decoder4 = conv_block(256 + 256, 256)  # up4(d5) (256) + e3 (256) -> 512 channels\n",
    "        self.decoder3 = conv_block(128 + 128, 128)  # up3(d4) (128) + e2 (128) -> 256 channels\n",
    "        self.decoder2 = conv_block(64 + 64, 64)     # up2(d3) (64) + e1 (64) -> 128 channels\n",
    "        self.decoder1 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "\n",
    "        # Refinement module for post-processing the output depth map\n",
    "        self.refinement = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Encoder pathway\n",
    "        e1 = self.encoder1(x)             # (B, 64, H, W)\n",
    "        e2 = self.encoder2(self.pool(e1))   # (B, 128, H/2, W/2)\n",
    "        e3 = self.encoder3(self.pool(e2))   # (B, 256, H/4, W/4)\n",
    "        e4 = self.encoder4(self.pool(e3))   # (B, 512, H/8, W/8)\n",
    "        e5 = self.encoder5(self.pool(e4))   # (B, 1024, H/16, W/16)\n",
    "\n",
    "        # Decoder pathway with transposed convolutions for upsampling and skip connections\n",
    "        d5 = self.decoder5(torch.cat([self.up5(e5), e4], dim=1))\n",
    "        d4 = self.decoder4(torch.cat([self.up4(d5), e3], dim=1))\n",
    "        d3 = self.decoder3(torch.cat([self.up3(d4), e2], dim=1))\n",
    "        d2 = self.decoder2(torch.cat([self.up2(d3), e1], dim=1))\n",
    "        d1 = self.decoder1(d2)\n",
    "        # Pass the output through the refinement module\n",
    "        refined = self.refinement(d1)\n",
    "        return torch.sigmoid(refined)\n",
    "\n",
    "\n",
    "# ------------------- Depth Loss with Sobel Edge Detection -------------------\n",
    "class DepthLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.ssim = SSIM(data_range=1.0, size_average=True, channel=1)\n",
    "        # Define Sobel kernels\n",
    "        sobel_x = torch.tensor([[-1, 0, 1],\n",
    "                                 [-2, 0, 2],\n",
    "                                 [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
    "        sobel_y = sobel_x.transpose(2, 3)\n",
    "        self.register_buffer(\"sobel_kernel_x\", sobel_x)\n",
    "        self.register_buffer(\"sobel_kernel_y\", sobel_y)\n",
    "\n",
    "    def sobel_edge(self, img: torch.Tensor) -> torch.Tensor:\n",
    "        kernel_x = self.sobel_kernel_x.to(img.device).to(img.dtype)\n",
    "        kernel_y = self.sobel_kernel_y.to(img.device).to(img.dtype)\n",
    "        if img.dim() == 3:\n",
    "            img = img.unsqueeze(1)\n",
    "        grad_x = torch.abs(nn.functional.conv2d(img, kernel_x, padding=1))\n",
    "        grad_y = torch.abs(nn.functional.conv2d(img, kernel_y, padding=1))\n",
    "        return grad_x + grad_y\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        edge_pred = self.sobel_edge(pred)\n",
    "        edge_target = self.sobel_edge(target)\n",
    "        edge_loss = torch.mean(torch.abs(edge_pred - edge_target))\n",
    "        return 0.4 * self.l1_loss(pred, target) + 0.4 * (1 - self.ssim(pred, target)) + 0.2 * edge_loss\n",
    "\n",
    "\n",
    "# ------------------- Training Function -------------------\n",
    "def train(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "          criterion: nn.Module, optimizer: optim.Optimizer, scheduler) -> None:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, depths in tqdm(train_loader, desc=f\"Epoch {epoch + 1} Training\"):\n",
    "            images, depths = images.to(DEVICE), depths.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, depths)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_VALUE)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Training Loss: {avg_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "\n",
    "# ------------------- Prediction and CSV Generation -------------------\n",
    "def generate_predictions(model: nn.Module, test_loader: DataLoader) -> None:\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, filenames in tqdm(test_loader, desc=\"Generating Predictions\"):\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images).squeeze(1).cpu().numpy()\n",
    "            for i, fname in enumerate(filenames):\n",
    "                output = (outputs[i] * 255).astype(np.uint8).flatten().tolist()\n",
    "                predictions.append([fname] + output)\n",
    "    columns = [\"ImageID\"] + [str(i) for i in range(IMAGE_SIZE * IMAGE_SIZE)]\n",
    "    df = pd.DataFrame(predictions, columns=columns)\n",
    "    df.insert(0, \"id\", range(len(df)))\n",
    "    df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "\n",
    "# ------------------- Main Execution -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    train_rgb_dir = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/images\"\n",
    "    train_depth_dir = \"/kaggle/input/depth-estimation/competition-data/competition-data/training/depths\"\n",
    "    val_rgb_dir = \"/kaggle/input/depth-estimation/competition-data/competition-data/validation/images\"\n",
    "    val_depth_dir = \"/kaggle/input/depth-estimation/competition-data/competition-data/validation/depths\"\n",
    "    test_rgb_dir = \"/kaggle/input/depth-estimation/competition-data/competition-data/testing/images\"\n",
    "\n",
    "    train_dataset = DepthDataset(train_rgb_dir, train_depth_dir, transform=train_transform)\n",
    "    val_dataset = DepthDataset(val_rgb_dir, val_depth_dir, transform=train_transform)\n",
    "    test_dataset = DepthDataset(test_rgb_dir, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    model = ModifiedUNet().to(DEVICE)\n",
    "    criterion = DepthLoss().to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, scheduler)\n",
    "    generate_predictions(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11466546,
     "isSourceIdPinned": false,
     "sourceId": 96480,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13897.279135,
   "end_time": "2025-03-30T07:42:10.250823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-30T03:50:32.971688",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
