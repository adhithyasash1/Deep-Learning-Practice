{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207f78bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:14:35.872601Z",
     "iopub.status.busy": "2025-03-19T18:14:35.872361Z",
     "iopub.status.idle": "2025-03-19T20:29:51.365413Z",
     "shell.execute_reply": "2025-03-19T20:29:51.364255Z"
    },
    "papermill": {
     "duration": 8115.497391,
     "end_time": "2025-03-19T20:29:51.366870",
     "exception": false,
     "start_time": "2025-03-19T18:14:35.869479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|██████████| 160M/160M [00:00<00:00, 222MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on cuda...\n",
      "Epoch 1/10\n",
      "----------\n",
      "Training Loss: 0.1896\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Training Loss: 0.1355\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Training Loss: 0.1315\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Training Loss: 0.1291\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Training Loss: 0.1266\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Training Loss: 0.1238\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Training Loss: 0.1215\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Training Loss: 0.1192\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Training Loss: 0.1171\n",
      "Saving best model weights\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Training Loss: 0.1147\n",
      "Saving best model weights\n",
      "\n",
      "Generating predictions...\n",
      "Generated submission with 525 predictions\n",
      "Model saved to outputs/mosquito_detection_model.pth\n",
      "Submission file generated: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms.functional as tf\n",
    "from torchvision.ops import nms\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    data_dir = \"/kaggle/input/dlp-object-detection-week-10/final_dlp_data/final_dlp_data\"\n",
    "    train_images_dir = os.path.join(data_dir, \"train\", \"images\")\n",
    "    train_labels_dir = os.path.join(data_dir, \"train\", \"labels\")\n",
    "    test_images_dir = os.path.join(data_dir, \"test\", \"images\")\n",
    "    output_dir = \"outputs\"\n",
    "    model_weights_file = os.path.join(output_dir, \"mosquito_detection_model.pth\")\n",
    "    \n",
    "    # Training parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 4\n",
    "    learning_rate = 1e-4\n",
    "    epochs = 10\n",
    "    \n",
    "    # Inference parameters\n",
    "    confidence_threshold = 0.5\n",
    "    nms_threshold = 0.5\n",
    "    \n",
    "    # Dataset parameters\n",
    "    image_size = 640  # Resize images to this size\n",
    "    \n",
    "    # Class mapping\n",
    "    class_names = {\n",
    "        0: \"aegypti\",\n",
    "        1: \"albopictus\",\n",
    "        2: \"anopheles\",\n",
    "        3: \"culex\",\n",
    "        4: \"culiseta\",\n",
    "        5: \"japonicus/koreicus\"\n",
    "    }\n",
    "    \n",
    "    num_classes = len(class_names) + 1  # +1 for background\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(Config.output_dir, exist_ok=True)\n",
    "\n",
    "# Custom Dataset for Mosquito Detection\n",
    "class MosquitoDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir=None, transforms=None, test_mode=False):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transforms = transforms\n",
    "        self.test_mode = test_mode\n",
    "        \n",
    "        # Get all image files\n",
    "        self.img_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.img_files[idx])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        original_height, original_width = img.shape[:2]\n",
    "        \n",
    "        # Resize image\n",
    "        img = cv2.resize(img, (Config.image_size, Config.image_size))\n",
    "        img = tf.to_tensor(img)\n",
    "        \n",
    "        # If test mode, just return the image and filename\n",
    "        if self.test_mode:\n",
    "            return img, self.img_files[idx]\n",
    "        \n",
    "        # Get corresponding label file\n",
    "        label_path = os.path.join(self.labels_dir, os.path.splitext(self.img_files[idx])[0] + '.txt')\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    data = line.strip().split()\n",
    "                    if len(data) == 5:\n",
    "                        # YOLO format: class_id, x_center, y_center, width, height (normalized)\n",
    "                        class_id = int(data[0])\n",
    "                        x_center = float(data[1])\n",
    "                        y_center = float(data[2])\n",
    "                        width = float(data[3])\n",
    "                        height = float(data[4])\n",
    "                        \n",
    "                        # Convert from YOLO format to x1, y1, x2, y2 format\n",
    "                        x1 = (x_center - width/2)\n",
    "                        y1 = (y_center - height/2)\n",
    "                        x2 = (x_center + width/2)\n",
    "                        y2 = (y_center + height/2)\n",
    "                        \n",
    "                        # Add box and label\n",
    "                        boxes.append([x1, y1, x2, y2])\n",
    "                        labels.append(class_id + 1)  # +1 because 0 is background in Faster R-CNN\n",
    "        \n",
    "        # Convert to tensor\n",
    "        if boxes:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        else:\n",
    "            # If no boxes, create empty tensors\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros(0, dtype=torch.int64)\n",
    "        \n",
    "        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        \n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd,\n",
    "            \"image_id\": torch.tensor([idx])\n",
    "        }\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Function to get the model\n",
    "def get_model(num_classes):\n",
    "    # Load a pre-trained Faster R-CNN model\n",
    "    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    \n",
    "    # Replace the classifier with a new one (num_classes including background)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_loader, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, targets in train_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += losses.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Training Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            print(\"Saving best model weights\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    torch.save(model.state_dict(), Config.model_weights_file)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Process outputs\n",
    "            for i, output in enumerate(outputs):\n",
    "                boxes = output['boxes'].cpu().numpy()\n",
    "                scores = output['scores'].cpu().numpy()\n",
    "                labels = output['labels'].cpu().numpy()\n",
    "                \n",
    "                # Filter by confidence threshold\n",
    "                keep_idxs = np.where(scores > Config.confidence_threshold)[0]\n",
    "                boxes = boxes[keep_idxs]\n",
    "                scores = scores[keep_idxs]\n",
    "                labels = labels[keep_idxs]\n",
    "                \n",
    "                # Display the first image with its detections\n",
    "                if i == 0:\n",
    "                    img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                    img = (img * 255).astype(np.uint8)\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 10))\n",
    "                    plt.imshow(img)\n",
    "                    \n",
    "                    for box, label, score in zip(boxes, labels, scores):\n",
    "                        x1, y1, x2, y2 = box.astype(int)\n",
    "                        class_name = Config.class_names.get(label-1, \"Unknown\")  # -1 because we added 1 for Faster R-CNN\n",
    "                        \n",
    "                        plt.gca().add_patch(\n",
    "                            plt.Rectangle((x1, y1), x2 - x1, y2 - y1, \n",
    "                                        fill=False, edgecolor='red', linewidth=2)\n",
    "                        )\n",
    "                        plt.text(x1, y1-10, f\"{class_name}: {score:.2f}\", \n",
    "                                bbox=dict(facecolor='red', alpha=0.5))\n",
    "                    \n",
    "                    plt.axis('off')\n",
    "                    plt.savefig(os.path.join(Config.output_dir, 'eval_example.png'))\n",
    "                    plt.close()\n",
    "                    break\n",
    "\n",
    "# Generate predictions for test set\n",
    "def generate_predictions(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in test_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Process outputs\n",
    "            for i, output in enumerate(outputs):\n",
    "                boxes = output['boxes'].cpu().numpy()\n",
    "                scores = output['scores'].cpu().numpy()\n",
    "                labels = output['labels'].cpu().numpy()\n",
    "                \n",
    "                # Filter by confidence threshold\n",
    "                keep_idxs = np.where(scores > Config.confidence_threshold)[0]\n",
    "                \n",
    "                if len(keep_idxs) > 0:\n",
    "                    boxes = boxes[keep_idxs]\n",
    "                    scores = scores[keep_idxs]\n",
    "                    labels = labels[keep_idxs]\n",
    "                    \n",
    "                    # Convert boxes from [x1, y1, x2, y2] to [x_center, y_center, width, height]\n",
    "                    x_centers = (boxes[:, 0] + boxes[:, 2]) / 2\n",
    "                    y_centers = (boxes[:, 1] + boxes[:, 3]) / 2\n",
    "                    widths = boxes[:, 2] - boxes[:, 0]\n",
    "                    heights = boxes[:, 3] - boxes[:, 1]\n",
    "                    \n",
    "                    for box_idx in range(len(boxes)):\n",
    "                        label_name = Config.class_names.get(labels[box_idx]-1, \"Unknown\")  # -1 because we added 1 for Faster R-CNN\n",
    "                        \n",
    "                        predictions.append({\n",
    "                            'ImageID': image_ids[i],\n",
    "                            'LabelName': label_name,\n",
    "                            'Conf': scores[box_idx],\n",
    "                            'xcenter': x_centers[box_idx],\n",
    "                            'ycenter': y_centers[box_idx],\n",
    "                            'bbx_width': widths[box_idx],\n",
    "                            'bbx_height': heights[box_idx]\n",
    "                        })\n",
    "                else:\n",
    "                    # If no detections, use default values with the first class\n",
    "                    predictions.append({\n",
    "                        'ImageID': image_ids[i],\n",
    "                        'LabelName': Config.class_names.get(0, \"Unknown\"),\n",
    "                        'Conf': Config.confidence_threshold,\n",
    "                        'xcenter': 0.5,\n",
    "                        'ycenter': 0.5,\n",
    "                        'bbx_width': 0.1,\n",
    "                        'bbx_height': 0.1\n",
    "                    })\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame(predictions)\n",
    "    submission_df.insert(0, 'id', range(len(submission_df)))\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(f\"Generated submission with {len(predictions)} predictions\")\n",
    "\n",
    "def main():\n",
    "    # Create datasets\n",
    "    train_dataset = MosquitoDataset(Config.train_images_dir, Config.train_labels_dir)\n",
    "    test_dataset = MosquitoDataset(Config.test_images_dir, test_mode=True)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2 if torch.cuda.is_available() else 0\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2 if torch.cuda.is_available() else 0\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = get_model(Config.num_classes)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        [param for param in model.parameters() if param.requires_grad],\n",
    "        lr=Config.learning_rate,\n",
    "        momentum=0.9,\n",
    "        weight_decay=5e-4\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Training model on {Config.device}...\")\n",
    "    model = train_model(model, train_loader, optimizer, Config.device, Config.epochs)\n",
    "    \n",
    "    # Generate predictions\n",
    "    print(\"Generating predictions...\")\n",
    "    generate_predictions(model, test_loader, Config.device)\n",
    "    \n",
    "    print(f\"Model saved to {Config.model_weights_file}\")\n",
    "    print(\"Submission file generated: submission.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c18942",
   "metadata": {
    "papermill": {
     "duration": 0.002423,
     "end_time": "2025-03-19T20:29:51.372402",
     "exception": false,
     "start_time": "2025-03-19T20:29:51.369979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11404671,
     "sourceId": 96038,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8119.86571,
   "end_time": "2025-03-19T20:29:53.105292",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T18:14:33.239582",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
