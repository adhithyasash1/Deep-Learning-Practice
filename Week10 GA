{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7ff047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T08:11:30.483621Z",
     "iopub.status.busy": "2025-03-24T08:11:30.483377Z",
     "iopub.status.idle": "2025-03-24T08:11:36.012661Z",
     "shell.execute_reply": "2025-03-24T08:11:36.011841Z"
    },
    "papermill": {
     "duration": 5.533365,
     "end_time": "2025-03-24T08:11:36.014292",
     "exception": false,
     "start_time": "2025-03-24T08:11:30.480927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.95-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\r\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Downloading ultralytics-8.3.95-py3-none-any.whl (949 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.95 ultralytics-thop-2.0.14\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics numpy pandas matplotlib pillow opencv-python pyyaml tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382e824c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T08:11:36.020238Z",
     "iopub.status.busy": "2025-03-24T08:11:36.019997Z",
     "iopub.status.idle": "2025-03-24T15:08:03.100435Z",
     "shell.execute_reply": "2025-03-24T15:08:03.098491Z"
    },
    "papermill": {
     "duration": 24987.086021,
     "end_time": "2025-03-24T15:08:03.102918",
     "exception": false,
     "start_time": "2025-03-24T08:11:36.016897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.5.1+cu121\n",
      "Preparing YOLO dataset structure...\n",
      "Training images: 6750, Validation images: 750\n",
      "Training YOLOv8 model using yolov8x.pt as base...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:00<00:00, 270MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.95 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=yolo_data/data.yaml, epochs=10, time=None, patience=100, batch=4, imgsz=1280, save=True, save_period=-1, cache=True, device=0, workers=4, project=outputs, name=mosquito_yolo, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.1, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.1, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=outputs/mosquito_yolo\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 17.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8723746  ultralytics.nn.modules.head.Detect           [6, [320, 640, 640]]          \n",
      "Model summary: 209 layers, 68,158,386 parameters, 68,158,370 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir outputs/mosquito_yolo', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 72.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_data/labels/train... 6750 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6750/6750 [00:05<00:00, 1213.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/yolo_data/images/train/120b30b0-c7db-4f0a-bead-a30424a65453.jpeg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolo_data/labels/train.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m35.5GB RAM required to cache images with 50% safety margin but only 28.3/31.4GB available, not caching images âš ï¸\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_data/labels/val... 750 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [00:00<00:00, 831.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolo_data/labels/val.cache\n",
      "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.5GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [00:16<00:00, 46.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to outputs/mosquito_yolo/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1moutputs/mosquito_yolo\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      12.6G      1.426      2.512      2.016          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:43<00:00,  1.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.547      0.289      0.277      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      12.4G      1.399      1.395      1.898          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:31<00:00,  1.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.862      0.202      0.214      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      12.4G      1.457      1.544      1.926          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:23<00:00,  1.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.867      0.229      0.248      0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      12.4G      1.482      1.521      1.948          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:18<00:00,  1.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.897      0.232      0.262      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      12.4G      1.378      1.395      1.853          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:13<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.924      0.239      0.286      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      12.4G      1.304      1.235      1.772          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:09<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750       0.58      0.368      0.328      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      12.4G      1.244       1.12      1.698          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:10<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.564      0.349      0.324      0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      12.4G      1.174      1.007      1.647          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:10<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.614      0.392      0.361      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      12.4G      1.126     0.9226      1.587          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:10<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.662      0.383      0.365      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      12.4G      1.087       0.87      1.546          1       1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [39:09<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.646      0.407       0.38       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 6.750 hours.\n",
      "Optimizer stripped from outputs/mosquito_yolo/weights/last.pt, 136.8MB\n",
      "Optimizer stripped from outputs/mosquito_yolo/weights/best.pt, 136.8MB\n",
      "\n",
      "Validating outputs/mosquito_yolo/weights/best.pt...\n",
      "Ultralytics 8.3.95 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 112 layers, 68,129,346 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [01:09<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.647      0.407       0.38       0.25\n",
      "               aegypti          5          5          1          0     0.0142    0.00895\n",
      "            albopictus        345        345      0.775      0.936      0.895      0.582\n",
      "             anopheles          5          5          1          0     0.0144     0.0122\n",
      "                 culex        318        318      0.653      0.931      0.858      0.569\n",
      "              culiseta         48         48      0.323      0.438      0.325      0.204\n",
      "    japonicus/koreicus         29         29      0.128      0.138      0.173      0.125\n",
      "Speed: 0.5ms preprocess, 88.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1moutputs/mosquito_yolo\u001b[0m\n",
      "Visualizing model predictions...\n",
      "\n",
      "image 1/1 /kaggle/working/yolo_data/images/val/ec6798dd-0dde-449e-8e61-da93489fe307.jpeg: 992x1280 1 culex, 189.2ms\n",
      "Speed: 12.3ms preprocess, 189.2ms inference, 1.5ms postprocess per image at shape (1, 3, 992, 1280)\n",
      "\n",
      "image 1/1 /kaggle/working/yolo_data/images/val/736c700d-c7ed-43f6-b5f6-899ee44a226a.jpeg: 1280x1216 1 albopictus, 238.3ms\n",
      "Speed: 8.9ms preprocess, 238.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1216)\n",
      "\n",
      "image 1/1 /kaggle/working/yolo_data/images/val/4ebb5a57-86b2-4cf8-a836-857b512b0d16.jpeg: 960x1280 1 culex, 184.5ms\n",
      "Speed: 9.1ms preprocess, 184.5ms inference, 1.3ms postprocess per image at shape (1, 3, 960, 1280)\n",
      "\n",
      "image 1/1 /kaggle/working/yolo_data/images/val/626e1b24-d2b6-4161-ad1d-48e9614f19da.jpeg: 736x1280 1 albopictus, 140.1ms\n",
      "Speed: 6.9ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "image 1/1 /kaggle/working/yolo_data/images/val/93c8d813-03e0-4cd1-b9a9-c950fe3c70d7.jpeg: 1280x960 1 albopictus, 184.8ms\n",
      "Speed: 6.4ms preprocess, 184.8ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 960)\n",
      "Generating predictions for test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997b5bcdfc144612857b0a90d379f160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test predictions:   0%|          | 0/525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 1 albopictus, 245.2ms\n",
      "Speed: 20.2ms preprocess, 245.2ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 245.3ms\n",
      "Speed: 19.7ms preprocess, 245.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 248.3ms\n",
      "Speed: 19.9ms preprocess, 248.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.7ms\n",
      "Speed: 17.5ms preprocess, 247.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.5ms\n",
      "Speed: 17.7ms preprocess, 246.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 246.2ms\n",
      "Speed: 18.1ms preprocess, 246.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.3ms\n",
      "Speed: 17.6ms preprocess, 249.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 249.1ms\n",
      "Speed: 17.7ms preprocess, 249.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.3ms\n",
      "Speed: 18.4ms preprocess, 247.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.3ms\n",
      "Speed: 18.2ms preprocess, 247.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 245.0ms\n",
      "Speed: 18.9ms preprocess, 245.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.7ms\n",
      "Speed: 18.4ms preprocess, 246.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.3ms\n",
      "Speed: 19.5ms preprocess, 248.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.7ms\n",
      "Speed: 20.7ms preprocess, 247.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.5ms\n",
      "Speed: 18.6ms preprocess, 246.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.7ms\n",
      "Speed: 19.0ms preprocess, 246.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 245.7ms\n",
      "Speed: 18.1ms preprocess, 245.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.0ms\n",
      "Speed: 17.5ms preprocess, 253.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.5ms\n",
      "Speed: 18.2ms preprocess, 249.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.7ms\n",
      "Speed: 19.8ms preprocess, 247.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.0ms\n",
      "Speed: 17.7ms preprocess, 253.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 253.1ms\n",
      "Speed: 19.7ms preprocess, 253.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.0ms\n",
      "Speed: 17.0ms preprocess, 252.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.6ms\n",
      "Speed: 18.1ms preprocess, 249.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.7ms\n",
      "Speed: 17.2ms preprocess, 248.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.3ms\n",
      "Speed: 17.4ms preprocess, 251.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 253.6ms\n",
      "Speed: 17.2ms preprocess, 253.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.7ms\n",
      "Speed: 17.2ms preprocess, 253.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.8ms\n",
      "Speed: 17.6ms preprocess, 252.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 250.4ms\n",
      "Speed: 18.0ms preprocess, 250.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 249.6ms\n",
      "Speed: 17.8ms preprocess, 249.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.9ms\n",
      "Speed: 17.9ms preprocess, 251.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.2ms\n",
      "Speed: 17.3ms preprocess, 252.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.3ms\n",
      "Speed: 17.3ms preprocess, 255.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.9ms\n",
      "Speed: 17.2ms preprocess, 253.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.9ms\n",
      "Speed: 17.9ms preprocess, 255.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 256.1ms\n",
      "Speed: 18.8ms preprocess, 256.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.9ms\n",
      "Speed: 20.6ms preprocess, 254.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.8ms\n",
      "Speed: 17.6ms preprocess, 255.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.4ms\n",
      "Speed: 17.3ms preprocess, 256.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.5ms\n",
      "Speed: 18.1ms preprocess, 254.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.4ms\n",
      "Speed: 17.1ms preprocess, 256.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 228.5ms\n",
      "Speed: 19.4ms preprocess, 228.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.1ms\n",
      "Speed: 17.3ms preprocess, 259.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.7ms\n",
      "Speed: 19.3ms preprocess, 254.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.7ms\n",
      "Speed: 17.5ms preprocess, 257.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.5ms\n",
      "Speed: 17.7ms preprocess, 259.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.0ms\n",
      "Speed: 17.3ms preprocess, 258.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.8ms\n",
      "Speed: 19.8ms preprocess, 258.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.5ms\n",
      "Speed: 20.0ms preprocess, 260.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.7ms\n",
      "Speed: 17.8ms preprocess, 260.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 260.2ms\n",
      "Speed: 18.0ms preprocess, 260.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 224.0ms\n",
      "Speed: 19.8ms preprocess, 224.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 261.4ms\n",
      "Speed: 17.0ms preprocess, 261.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.7ms\n",
      "Speed: 17.3ms preprocess, 260.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.7ms\n",
      "Speed: 17.2ms preprocess, 261.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.7ms\n",
      "Speed: 17.5ms preprocess, 263.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.8ms\n",
      "Speed: 17.3ms preprocess, 260.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.5ms\n",
      "Speed: 17.3ms preprocess, 261.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.3ms\n",
      "Speed: 17.5ms preprocess, 262.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 262.0ms\n",
      "Speed: 17.8ms preprocess, 262.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.9ms\n",
      "Speed: 17.4ms preprocess, 260.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 263.4ms\n",
      "Speed: 18.2ms preprocess, 263.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 264.0ms\n",
      "Speed: 18.1ms preprocess, 264.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 260.6ms\n",
      "Speed: 18.2ms preprocess, 260.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.7ms\n",
      "Speed: 18.7ms preprocess, 262.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.3ms\n",
      "Speed: 17.8ms preprocess, 262.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.6ms\n",
      "Speed: 21.7ms preprocess, 263.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 265.9ms\n",
      "Speed: 20.1ms preprocess, 265.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.6ms\n",
      "Speed: 17.7ms preprocess, 263.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.2ms\n",
      "Speed: 17.6ms preprocess, 262.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 266.2ms\n",
      "Speed: 17.1ms preprocess, 266.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.9ms\n",
      "Speed: 20.3ms preprocess, 263.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.4ms\n",
      "Speed: 18.3ms preprocess, 262.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 270.6ms\n",
      "Speed: 18.1ms preprocess, 270.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 265.9ms\n",
      "Speed: 18.7ms preprocess, 265.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.1ms\n",
      "Speed: 18.2ms preprocess, 262.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 266.5ms\n",
      "Speed: 18.0ms preprocess, 266.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 266.3ms\n",
      "Speed: 20.0ms preprocess, 266.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 266.7ms\n",
      "Speed: 18.2ms preprocess, 266.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 263.6ms\n",
      "Speed: 18.2ms preprocess, 263.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 264.5ms\n",
      "Speed: 17.3ms preprocess, 264.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 264.7ms\n",
      "Speed: 19.0ms preprocess, 264.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 266.8ms\n",
      "Speed: 19.0ms preprocess, 266.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 264.5ms\n",
      "Speed: 19.4ms preprocess, 264.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.2ms\n",
      "Speed: 16.3ms preprocess, 263.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 265.6ms\n",
      "Speed: 18.1ms preprocess, 265.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 269.0ms\n",
      "Speed: 18.3ms preprocess, 269.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 267.4ms\n",
      "Speed: 16.7ms preprocess, 267.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 266.9ms\n",
      "Speed: 16.8ms preprocess, 266.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 263.9ms\n",
      "Speed: 19.3ms preprocess, 263.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.0ms\n",
      "Speed: 17.3ms preprocess, 263.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 268.5ms\n",
      "Speed: 18.0ms preprocess, 268.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 266.1ms\n",
      "Speed: 17.1ms preprocess, 266.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 265.4ms\n",
      "Speed: 17.8ms preprocess, 265.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 1 culex, 269.1ms\n",
      "Speed: 18.9ms preprocess, 269.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 265.6ms\n",
      "Speed: 18.4ms preprocess, 265.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 4 albopictuss, 264.8ms\n",
      "Speed: 17.0ms preprocess, 264.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 266.5ms\n",
      "Speed: 19.3ms preprocess, 266.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 265.8ms\n",
      "Speed: 17.0ms preprocess, 265.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 267.4ms\n",
      "Speed: 18.0ms preprocess, 267.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.8ms\n",
      "Speed: 17.6ms preprocess, 263.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.4ms\n",
      "Speed: 18.4ms preprocess, 263.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 1 culex, 1 culiseta, 263.0ms\n",
      "Speed: 19.8ms preprocess, 263.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 267.7ms\n",
      "Speed: 19.8ms preprocess, 267.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 267.3ms\n",
      "Speed: 20.5ms preprocess, 267.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 265.3ms\n",
      "Speed: 19.4ms preprocess, 265.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 266.5ms\n",
      "Speed: 19.6ms preprocess, 266.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 263.3ms\n",
      "Speed: 17.2ms preprocess, 263.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 264.7ms\n",
      "Speed: 19.8ms preprocess, 264.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 264.5ms\n",
      "Speed: 18.9ms preprocess, 264.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 264.6ms\n",
      "Speed: 17.7ms preprocess, 264.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.6ms\n",
      "Speed: 17.2ms preprocess, 263.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.2ms\n",
      "Speed: 20.3ms preprocess, 261.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.6ms\n",
      "Speed: 16.9ms preprocess, 263.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 263.2ms\n",
      "Speed: 16.9ms preprocess, 263.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.9ms\n",
      "Speed: 17.4ms preprocess, 259.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 264.5ms\n",
      "Speed: 18.3ms preprocess, 264.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 262.3ms\n",
      "Speed: 17.8ms preprocess, 262.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.2ms\n",
      "Speed: 19.1ms preprocess, 261.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.7ms\n",
      "Speed: 17.5ms preprocess, 262.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 262.6ms\n",
      "Speed: 18.3ms preprocess, 262.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 1 culiseta, 261.6ms\n",
      "Speed: 17.4ms preprocess, 261.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 261.5ms\n",
      "Speed: 17.5ms preprocess, 261.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 260.1ms\n",
      "Speed: 17.9ms preprocess, 260.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.4ms\n",
      "Speed: 18.1ms preprocess, 258.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.7ms\n",
      "Speed: 17.6ms preprocess, 259.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.7ms\n",
      "Speed: 17.6ms preprocess, 259.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.6ms\n",
      "Speed: 17.0ms preprocess, 258.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.2ms\n",
      "Speed: 17.6ms preprocess, 258.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.5ms\n",
      "Speed: 17.0ms preprocess, 259.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.8ms\n",
      "Speed: 16.7ms preprocess, 258.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.1ms\n",
      "Speed: 17.9ms preprocess, 261.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.6ms\n",
      "Speed: 17.0ms preprocess, 258.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 257.8ms\n",
      "Speed: 17.0ms preprocess, 257.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.4ms\n",
      "Speed: 17.3ms preprocess, 258.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 256.2ms\n",
      "Speed: 18.9ms preprocess, 256.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 257.0ms\n",
      "Speed: 19.6ms preprocess, 257.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.4ms\n",
      "Speed: 17.5ms preprocess, 260.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.6ms\n",
      "Speed: 17.8ms preprocess, 257.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.8ms\n",
      "Speed: 17.7ms preprocess, 256.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 256.9ms\n",
      "Speed: 18.0ms preprocess, 256.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.3ms\n",
      "Speed: 18.0ms preprocess, 258.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.4ms\n",
      "Speed: 19.7ms preprocess, 255.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 256.8ms\n",
      "Speed: 17.7ms preprocess, 256.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.2ms\n",
      "Speed: 19.8ms preprocess, 254.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.7ms\n",
      "Speed: 20.2ms preprocess, 253.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 255.3ms\n",
      "Speed: 19.8ms preprocess, 255.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.2ms\n",
      "Speed: 19.3ms preprocess, 256.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.7ms\n",
      "Speed: 19.8ms preprocess, 256.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.1ms\n",
      "Speed: 20.1ms preprocess, 253.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.1ms\n",
      "Speed: 18.2ms preprocess, 255.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 21.1ms preprocess, 254.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.6ms\n",
      "Speed: 22.1ms preprocess, 251.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.5ms\n",
      "Speed: 17.4ms preprocess, 252.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 253.7ms\n",
      "Speed: 19.4ms preprocess, 253.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.4ms\n",
      "Speed: 17.3ms preprocess, 251.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.5ms\n",
      "Speed: 17.7ms preprocess, 250.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.7ms\n",
      "Speed: 19.3ms preprocess, 252.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.9ms\n",
      "Speed: 17.7ms preprocess, 250.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.2ms\n",
      "Speed: 19.6ms preprocess, 254.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.2ms\n",
      "Speed: 17.9ms preprocess, 254.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.7ms\n",
      "Speed: 16.9ms preprocess, 255.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.7ms\n",
      "Speed: 17.4ms preprocess, 251.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.9ms\n",
      "Speed: 18.8ms preprocess, 252.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.4ms\n",
      "Speed: 17.6ms preprocess, 254.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 265.2ms\n",
      "Speed: 17.9ms preprocess, 265.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.6ms\n",
      "Speed: 17.6ms preprocess, 248.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.8ms\n",
      "Speed: 17.9ms preprocess, 252.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.3ms\n",
      "Speed: 18.0ms preprocess, 253.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 253.9ms\n",
      "Speed: 16.9ms preprocess, 253.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 253.9ms\n",
      "Speed: 17.3ms preprocess, 253.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.8ms\n",
      "Speed: 18.6ms preprocess, 250.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.4ms\n",
      "Speed: 20.0ms preprocess, 248.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.6ms\n",
      "Speed: 20.2ms preprocess, 249.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.8ms\n",
      "Speed: 18.9ms preprocess, 252.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.6ms\n",
      "Speed: 16.9ms preprocess, 251.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.1ms\n",
      "Speed: 17.7ms preprocess, 254.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.8ms\n",
      "Speed: 17.5ms preprocess, 252.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.0ms\n",
      "Speed: 18.7ms preprocess, 253.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.6ms\n",
      "Speed: 17.0ms preprocess, 247.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.9ms\n",
      "Speed: 17.5ms preprocess, 246.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.5ms\n",
      "Speed: 17.5ms preprocess, 253.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.4ms\n",
      "Speed: 16.9ms preprocess, 248.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.8ms\n",
      "Speed: 17.7ms preprocess, 246.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 247.3ms\n",
      "Speed: 16.8ms preprocess, 247.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.2ms\n",
      "Speed: 17.6ms preprocess, 252.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.2ms\n",
      "Speed: 17.8ms preprocess, 250.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.1ms\n",
      "Speed: 17.7ms preprocess, 248.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.4ms\n",
      "Speed: 17.5ms preprocess, 250.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.8ms\n",
      "Speed: 18.2ms preprocess, 250.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.6ms\n",
      "Speed: 17.8ms preprocess, 248.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 247.3ms\n",
      "Speed: 17.5ms preprocess, 247.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.9ms\n",
      "Speed: 18.2ms preprocess, 247.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.5ms\n",
      "Speed: 19.0ms preprocess, 252.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.0ms\n",
      "Speed: 18.7ms preprocess, 246.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.9ms\n",
      "Speed: 17.8ms preprocess, 249.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.0ms\n",
      "Speed: 17.7ms preprocess, 251.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.3ms\n",
      "Speed: 17.7ms preprocess, 249.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 248.5ms\n",
      "Speed: 18.3ms preprocess, 248.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.0ms\n",
      "Speed: 17.5ms preprocess, 248.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.1ms\n",
      "Speed: 17.4ms preprocess, 250.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.0ms\n",
      "Speed: 18.9ms preprocess, 250.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.2ms\n",
      "Speed: 17.5ms preprocess, 248.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 244.4ms\n",
      "Speed: 18.1ms preprocess, 244.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.9ms\n",
      "Speed: 17.8ms preprocess, 249.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.2ms\n",
      "Speed: 18.3ms preprocess, 247.2ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.1ms\n",
      "Speed: 17.8ms preprocess, 250.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.2ms\n",
      "Speed: 18.4ms preprocess, 246.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.0ms\n",
      "Speed: 17.7ms preprocess, 250.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.1ms\n",
      "Speed: 19.8ms preprocess, 252.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.2ms\n",
      "Speed: 20.6ms preprocess, 249.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.8ms\n",
      "Speed: 18.4ms preprocess, 250.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.3ms\n",
      "Speed: 17.9ms preprocess, 251.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.1ms\n",
      "Speed: 17.5ms preprocess, 247.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.5ms\n",
      "Speed: 17.8ms preprocess, 249.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.7ms\n",
      "Speed: 17.8ms preprocess, 248.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.6ms\n",
      "Speed: 17.5ms preprocess, 249.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 249.4ms\n",
      "Speed: 17.2ms preprocess, 249.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.4ms\n",
      "Speed: 18.4ms preprocess, 248.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.8ms\n",
      "Speed: 18.3ms preprocess, 247.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 248.3ms\n",
      "Speed: 18.0ms preprocess, 248.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.5ms\n",
      "Speed: 17.6ms preprocess, 248.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.1ms\n",
      "Speed: 18.0ms preprocess, 251.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.9ms\n",
      "Speed: 17.3ms preprocess, 250.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.4ms\n",
      "Speed: 17.1ms preprocess, 249.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.0ms\n",
      "Speed: 17.0ms preprocess, 247.0ms inference, 1.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.3ms\n",
      "Speed: 17.8ms preprocess, 251.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.1ms\n",
      "Speed: 18.1ms preprocess, 250.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.3ms\n",
      "Speed: 17.8ms preprocess, 249.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.5ms\n",
      "Speed: 17.5ms preprocess, 250.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.0ms\n",
      "Speed: 17.5ms preprocess, 249.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 249.5ms\n",
      "Speed: 17.8ms preprocess, 249.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.4ms\n",
      "Speed: 17.9ms preprocess, 250.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.6ms\n",
      "Speed: 17.5ms preprocess, 246.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 1 culex, 246.2ms\n",
      "Speed: 17.3ms preprocess, 246.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.8ms\n",
      "Speed: 30.3ms preprocess, 246.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.4ms\n",
      "Speed: 26.5ms preprocess, 246.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.2ms\n",
      "Speed: 17.7ms preprocess, 250.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.1ms\n",
      "Speed: 21.5ms preprocess, 248.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.1ms\n",
      "Speed: 17.9ms preprocess, 252.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 248.3ms\n",
      "Speed: 31.1ms preprocess, 248.3ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.2ms\n",
      "Speed: 20.0ms preprocess, 248.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.7ms\n",
      "Speed: 20.1ms preprocess, 249.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 245.4ms\n",
      "Speed: 19.9ms preprocess, 245.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 249.7ms\n",
      "Speed: 17.2ms preprocess, 249.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.4ms\n",
      "Speed: 18.0ms preprocess, 251.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.4ms\n",
      "Speed: 16.9ms preprocess, 249.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 248.9ms\n",
      "Speed: 18.2ms preprocess, 248.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.7ms\n",
      "Speed: 18.9ms preprocess, 246.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.3ms\n",
      "Speed: 17.9ms preprocess, 252.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.7ms\n",
      "Speed: 17.0ms preprocess, 247.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 245.6ms\n",
      "Speed: 17.1ms preprocess, 245.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 251.6ms\n",
      "Speed: 17.3ms preprocess, 251.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.2ms\n",
      "Speed: 18.2ms preprocess, 252.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.1ms\n",
      "Speed: 18.0ms preprocess, 247.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.8ms\n",
      "Speed: 18.8ms preprocess, 250.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 247.8ms\n",
      "Speed: 17.3ms preprocess, 247.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.6ms\n",
      "Speed: 18.4ms preprocess, 248.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.8ms\n",
      "Speed: 17.6ms preprocess, 247.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 245.0ms\n",
      "Speed: 17.9ms preprocess, 245.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.8ms\n",
      "Speed: 18.4ms preprocess, 250.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.9ms\n",
      "Speed: 18.4ms preprocess, 252.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 247.2ms\n",
      "Speed: 17.7ms preprocess, 247.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.9ms\n",
      "Speed: 18.1ms preprocess, 252.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.3ms\n",
      "Speed: 18.1ms preprocess, 248.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 251.4ms\n",
      "Speed: 18.2ms preprocess, 251.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.5ms\n",
      "Speed: 17.9ms preprocess, 252.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 251.2ms\n",
      "Speed: 19.4ms preprocess, 251.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.0ms\n",
      "Speed: 20.1ms preprocess, 249.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.7ms\n",
      "Speed: 17.7ms preprocess, 250.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 247.8ms\n",
      "Speed: 17.8ms preprocess, 247.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.0ms\n",
      "Speed: 17.8ms preprocess, 250.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.5ms\n",
      "Speed: 17.3ms preprocess, 250.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.4ms\n",
      "Speed: 17.1ms preprocess, 254.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.8ms\n",
      "Speed: 17.7ms preprocess, 250.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.2ms\n",
      "Speed: 18.3ms preprocess, 250.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.1ms\n",
      "Speed: 19.9ms preprocess, 250.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.5ms\n",
      "Speed: 17.5ms preprocess, 250.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 250.7ms\n",
      "Speed: 19.2ms preprocess, 250.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 17.7ms preprocess, 254.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 17.4ms preprocess, 254.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.5ms\n",
      "Speed: 18.5ms preprocess, 253.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 18.3ms preprocess, 254.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 253.0ms\n",
      "Speed: 17.4ms preprocess, 253.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.3ms\n",
      "Speed: 17.5ms preprocess, 251.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.5ms\n",
      "Speed: 17.6ms preprocess, 253.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.3ms\n",
      "Speed: 17.5ms preprocess, 250.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 251.3ms\n",
      "Speed: 17.5ms preprocess, 251.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.6ms\n",
      "Speed: 17.0ms preprocess, 251.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 1 culex, 255.0ms\n",
      "Speed: 17.6ms preprocess, 255.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.6ms\n",
      "Speed: 17.5ms preprocess, 253.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.1ms\n",
      "Speed: 27.1ms preprocess, 251.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.7ms\n",
      "Speed: 18.3ms preprocess, 254.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.2ms\n",
      "Speed: 17.6ms preprocess, 252.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.0ms\n",
      "Speed: 17.7ms preprocess, 252.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.4ms\n",
      "Speed: 18.0ms preprocess, 252.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.1ms\n",
      "Speed: 17.0ms preprocess, 253.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.0ms\n",
      "Speed: 18.8ms preprocess, 255.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.8ms\n",
      "Speed: 17.5ms preprocess, 253.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.9ms\n",
      "Speed: 17.5ms preprocess, 253.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.9ms\n",
      "Speed: 19.5ms preprocess, 252.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.4ms\n",
      "Speed: 17.9ms preprocess, 253.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.6ms\n",
      "Speed: 18.0ms preprocess, 254.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 256.1ms\n",
      "Speed: 18.7ms preprocess, 256.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.6ms\n",
      "Speed: 17.8ms preprocess, 255.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.4ms\n",
      "Speed: 18.5ms preprocess, 256.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.8ms\n",
      "Speed: 17.9ms preprocess, 252.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 255.8ms\n",
      "Speed: 16.9ms preprocess, 255.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.0ms\n",
      "Speed: 17.9ms preprocess, 258.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.2ms\n",
      "Speed: 17.6ms preprocess, 255.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.6ms\n",
      "Speed: 17.6ms preprocess, 254.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.0ms\n",
      "Speed: 17.3ms preprocess, 256.0ms inference, 1.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.9ms\n",
      "Speed: 17.3ms preprocess, 255.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.7ms\n",
      "Speed: 17.4ms preprocess, 257.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.2ms\n",
      "Speed: 17.5ms preprocess, 257.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.6ms\n",
      "Speed: 17.5ms preprocess, 253.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.4ms\n",
      "Speed: 18.1ms preprocess, 258.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.8ms\n",
      "Speed: 19.6ms preprocess, 257.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.0ms\n",
      "Speed: 17.2ms preprocess, 256.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.7ms\n",
      "Speed: 17.8ms preprocess, 257.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.2ms\n",
      "Speed: 19.6ms preprocess, 259.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 17.7ms preprocess, 254.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.9ms\n",
      "Speed: 17.0ms preprocess, 259.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.9ms\n",
      "Speed: 17.5ms preprocess, 256.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.5ms\n",
      "Speed: 16.8ms preprocess, 258.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.3ms\n",
      "Speed: 17.8ms preprocess, 256.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.2ms\n",
      "Speed: 30.1ms preprocess, 256.2ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.0ms\n",
      "Speed: 30.9ms preprocess, 260.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.4ms\n",
      "Speed: 30.5ms preprocess, 256.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.2ms\n",
      "Speed: 19.6ms preprocess, 258.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.5ms\n",
      "Speed: 17.2ms preprocess, 258.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.8ms\n",
      "Speed: 17.8ms preprocess, 257.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.3ms\n",
      "Speed: 17.1ms preprocess, 258.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.5ms\n",
      "Speed: 17.2ms preprocess, 259.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.0ms\n",
      "Speed: 17.3ms preprocess, 257.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.8ms\n",
      "Speed: 20.0ms preprocess, 257.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.0ms\n",
      "Speed: 19.4ms preprocess, 258.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.3ms\n",
      "Speed: 17.7ms preprocess, 258.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.6ms\n",
      "Speed: 17.6ms preprocess, 255.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.1ms\n",
      "Speed: 17.5ms preprocess, 259.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.0ms\n",
      "Speed: 17.4ms preprocess, 259.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 257.4ms\n",
      "Speed: 16.9ms preprocess, 257.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.2ms\n",
      "Speed: 17.5ms preprocess, 258.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.8ms\n",
      "Speed: 17.0ms preprocess, 259.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.9ms\n",
      "Speed: 17.1ms preprocess, 258.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.6ms\n",
      "Speed: 17.7ms preprocess, 259.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 257.5ms\n",
      "Speed: 18.1ms preprocess, 257.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.4ms\n",
      "Speed: 16.9ms preprocess, 259.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.6ms\n",
      "Speed: 17.7ms preprocess, 260.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.3ms\n",
      "Speed: 18.2ms preprocess, 260.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 257.7ms\n",
      "Speed: 17.9ms preprocess, 257.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.9ms\n",
      "Speed: 19.2ms preprocess, 259.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.6ms\n",
      "Speed: 17.8ms preprocess, 259.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.9ms\n",
      "Speed: 17.5ms preprocess, 260.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.7ms\n",
      "Speed: 17.8ms preprocess, 256.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.9ms\n",
      "Speed: 17.6ms preprocess, 259.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.9ms\n",
      "Speed: 17.5ms preprocess, 257.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 260.0ms\n",
      "Speed: 17.8ms preprocess, 260.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.8ms\n",
      "Speed: 19.3ms preprocess, 260.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.2ms\n",
      "Speed: 21.1ms preprocess, 261.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 263.9ms\n",
      "Speed: 19.5ms preprocess, 263.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.9ms\n",
      "Speed: 16.9ms preprocess, 260.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.3ms\n",
      "Speed: 17.6ms preprocess, 260.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.4ms\n",
      "Speed: 17.2ms preprocess, 258.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.8ms\n",
      "Speed: 19.3ms preprocess, 257.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.5ms\n",
      "Speed: 17.5ms preprocess, 256.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.8ms\n",
      "Speed: 17.0ms preprocess, 260.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 1 culex, 1 culiseta, 260.4ms\n",
      "Speed: 17.6ms preprocess, 260.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.7ms\n",
      "Speed: 17.1ms preprocess, 259.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.3ms\n",
      "Speed: 17.7ms preprocess, 258.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.8ms\n",
      "Speed: 19.9ms preprocess, 260.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.3ms\n",
      "Speed: 17.0ms preprocess, 261.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.1ms\n",
      "Speed: 24.9ms preprocess, 261.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.0ms\n",
      "Speed: 17.8ms preprocess, 261.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.4ms\n",
      "Speed: 19.6ms preprocess, 259.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 259.2ms\n",
      "Speed: 18.0ms preprocess, 259.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.2ms\n",
      "Speed: 17.4ms preprocess, 259.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.6ms\n",
      "Speed: 20.3ms preprocess, 259.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.5ms\n",
      "Speed: 17.3ms preprocess, 259.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 256.0ms\n",
      "Speed: 18.4ms preprocess, 256.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 306.4ms\n",
      "Speed: 17.3ms preprocess, 306.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.7ms\n",
      "Speed: 17.3ms preprocess, 254.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.1ms\n",
      "Speed: 17.3ms preprocess, 256.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.5ms\n",
      "Speed: 17.4ms preprocess, 254.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.9ms\n",
      "Speed: 18.0ms preprocess, 254.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 251.4ms\n",
      "Speed: 17.3ms preprocess, 251.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.7ms\n",
      "Speed: 19.2ms preprocess, 252.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.3ms\n",
      "Speed: 16.9ms preprocess, 253.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.3ms\n",
      "Speed: 17.4ms preprocess, 255.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.4ms\n",
      "Speed: 17.8ms preprocess, 256.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.7ms\n",
      "Speed: 17.7ms preprocess, 255.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 2 albopictuss, 253.1ms\n",
      "Speed: 17.7ms preprocess, 253.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.5ms\n",
      "Speed: 18.0ms preprocess, 254.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.4ms\n",
      "Speed: 19.6ms preprocess, 254.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.8ms\n",
      "Speed: 17.7ms preprocess, 252.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.1ms\n",
      "Speed: 17.5ms preprocess, 256.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 252.5ms\n",
      "Speed: 18.3ms preprocess, 252.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.0ms\n",
      "Speed: 17.7ms preprocess, 254.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.9ms\n",
      "Speed: 30.7ms preprocess, 254.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.1ms\n",
      "Speed: 19.8ms preprocess, 254.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.4ms\n",
      "Speed: 20.5ms preprocess, 253.4ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.8ms\n",
      "Speed: 19.6ms preprocess, 250.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 19.7ms preprocess, 254.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.2ms\n",
      "Speed: 19.3ms preprocess, 253.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 282.3ms\n",
      "Speed: 17.3ms preprocess, 282.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.8ms\n",
      "Speed: 17.8ms preprocess, 251.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 249.9ms\n",
      "Speed: 18.0ms preprocess, 249.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.9ms\n",
      "Speed: 17.8ms preprocess, 252.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.0ms\n",
      "Speed: 17.8ms preprocess, 254.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 246.2ms\n",
      "Speed: 20.1ms preprocess, 246.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 248.6ms\n",
      "Speed: 17.5ms preprocess, 248.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.6ms\n",
      "Speed: 16.9ms preprocess, 253.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.5ms\n",
      "Speed: 17.4ms preprocess, 252.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.9ms\n",
      "Speed: 17.7ms preprocess, 251.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.9ms\n",
      "Speed: 17.1ms preprocess, 250.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.8ms\n",
      "Speed: 18.1ms preprocess, 247.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.8ms\n",
      "Speed: 17.9ms preprocess, 249.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.8ms\n",
      "Speed: 17.5ms preprocess, 248.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.9ms\n",
      "Speed: 17.7ms preprocess, 250.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.6ms\n",
      "Speed: 16.6ms preprocess, 253.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.8ms\n",
      "Speed: 17.3ms preprocess, 251.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 249.9ms\n",
      "Speed: 17.4ms preprocess, 249.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.3ms\n",
      "Speed: 17.6ms preprocess, 253.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.9ms\n",
      "Speed: 18.1ms preprocess, 252.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.6ms\n",
      "Speed: 17.5ms preprocess, 249.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.1ms\n",
      "Speed: 16.8ms preprocess, 250.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.6ms\n",
      "Speed: 17.5ms preprocess, 251.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.4ms\n",
      "Speed: 19.4ms preprocess, 252.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.2ms\n",
      "Speed: 16.7ms preprocess, 250.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 253.1ms\n",
      "Speed: 17.6ms preprocess, 253.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.2ms\n",
      "Speed: 17.1ms preprocess, 250.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 249.6ms\n",
      "Speed: 17.0ms preprocess, 249.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.2ms\n",
      "Speed: 17.1ms preprocess, 253.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.1ms\n",
      "Speed: 18.5ms preprocess, 251.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.1ms\n",
      "Speed: 17.9ms preprocess, 252.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.0ms\n",
      "Speed: 20.0ms preprocess, 249.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.3ms\n",
      "Speed: 16.9ms preprocess, 252.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.9ms\n",
      "Speed: 16.8ms preprocess, 248.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.7ms\n",
      "Speed: 17.4ms preprocess, 248.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 248.5ms\n",
      "Speed: 17.9ms preprocess, 248.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.9ms\n",
      "Speed: 17.9ms preprocess, 253.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.5ms\n",
      "Speed: 18.8ms preprocess, 250.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.7ms\n",
      "Speed: 20.1ms preprocess, 250.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.1ms\n",
      "Speed: 17.2ms preprocess, 252.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 250.6ms\n",
      "Speed: 17.8ms preprocess, 250.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.1ms\n",
      "Speed: 17.7ms preprocess, 251.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.6ms\n",
      "Speed: 17.7ms preprocess, 253.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 247.6ms\n",
      "Speed: 17.2ms preprocess, 247.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.1ms\n",
      "Speed: 17.7ms preprocess, 251.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 251.0ms\n",
      "Speed: 17.9ms preprocess, 251.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.1ms\n",
      "Speed: 19.7ms preprocess, 254.1ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 249.7ms\n",
      "Speed: 20.6ms preprocess, 249.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.4ms\n",
      "Speed: 17.6ms preprocess, 252.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 247.8ms\n",
      "Speed: 17.8ms preprocess, 247.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.6ms\n",
      "Speed: 17.4ms preprocess, 255.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.0ms\n",
      "Speed: 17.5ms preprocess, 252.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.3ms\n",
      "Speed: 16.9ms preprocess, 255.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.7ms\n",
      "Speed: 17.3ms preprocess, 255.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 252.0ms\n",
      "Speed: 18.1ms preprocess, 252.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.1ms\n",
      "Speed: 18.2ms preprocess, 255.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 250.7ms\n",
      "Speed: 18.2ms preprocess, 250.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.5ms\n",
      "Speed: 18.3ms preprocess, 254.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 251.4ms\n",
      "Speed: 18.2ms preprocess, 251.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 253.5ms\n",
      "Speed: 17.9ms preprocess, 253.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.7ms\n",
      "Speed: 17.1ms preprocess, 255.7ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.5ms\n",
      "Speed: 17.3ms preprocess, 254.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 256.0ms\n",
      "Speed: 17.2ms preprocess, 256.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.0ms\n",
      "Speed: 20.3ms preprocess, 254.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 34.0ms preprocess, 254.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 255.5ms\n",
      "Speed: 31.5ms preprocess, 255.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.8ms\n",
      "Speed: 30.8ms preprocess, 257.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.3ms\n",
      "Speed: 17.2ms preprocess, 257.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.8ms\n",
      "Speed: 17.0ms preprocess, 256.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.1ms\n",
      "Speed: 18.0ms preprocess, 255.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.6ms\n",
      "Speed: 23.8ms preprocess, 256.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.4ms\n",
      "Speed: 18.1ms preprocess, 258.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 255.2ms\n",
      "Speed: 17.5ms preprocess, 255.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culiseta, 255.2ms\n",
      "Speed: 17.3ms preprocess, 255.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.9ms\n",
      "Speed: 18.5ms preprocess, 256.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.6ms\n",
      "Speed: 18.0ms preprocess, 256.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.9ms\n",
      "Speed: 17.7ms preprocess, 257.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.2ms\n",
      "Speed: 19.2ms preprocess, 259.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.7ms\n",
      "Speed: 18.0ms preprocess, 259.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.3ms\n",
      "Speed: 23.2ms preprocess, 258.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.8ms\n",
      "Speed: 17.4ms preprocess, 260.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 culex, 258.0ms\n",
      "Speed: 18.6ms preprocess, 258.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.8ms\n",
      "Speed: 20.3ms preprocess, 257.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.5ms\n",
      "Speed: 18.2ms preprocess, 258.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.9ms\n",
      "Speed: 17.4ms preprocess, 257.9ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.6ms\n",
      "Speed: 18.0ms preprocess, 259.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.5ms\n",
      "Speed: 17.6ms preprocess, 258.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.6ms\n",
      "Speed: 18.0ms preprocess, 259.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.8ms\n",
      "Speed: 17.1ms preprocess, 258.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.3ms\n",
      "Speed: 17.5ms preprocess, 259.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.8ms\n",
      "Speed: 18.3ms preprocess, 258.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.7ms\n",
      "Speed: 17.8ms preprocess, 260.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.8ms\n",
      "Speed: 18.3ms preprocess, 259.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 1 culex, 259.8ms\n",
      "Speed: 18.1ms preprocess, 259.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.0ms\n",
      "Speed: 17.8ms preprocess, 259.0ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.5ms\n",
      "Speed: 18.2ms preprocess, 261.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.5ms\n",
      "Speed: 19.5ms preprocess, 258.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.6ms\n",
      "Speed: 18.4ms preprocess, 258.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.6ms\n",
      "Speed: 18.0ms preprocess, 259.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.4ms\n",
      "Speed: 17.4ms preprocess, 258.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.9ms\n",
      "Speed: 18.0ms preprocess, 259.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 260.5ms\n",
      "Speed: 18.3ms preprocess, 260.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 4 albopictuss, 259.4ms\n",
      "Speed: 17.7ms preprocess, 259.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.4ms\n",
      "Speed: 17.4ms preprocess, 261.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 258.9ms\n",
      "Speed: 18.4ms preprocess, 258.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.7ms\n",
      "Speed: 19.9ms preprocess, 257.7ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 259.6ms\n",
      "Speed: 19.5ms preprocess, 259.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.4ms\n",
      "Speed: 17.4ms preprocess, 258.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 261.9ms\n",
      "Speed: 17.4ms preprocess, 261.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.5ms\n",
      "Speed: 18.1ms preprocess, 257.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.7ms\n",
      "Speed: 18.4ms preprocess, 256.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 259.4ms\n",
      "Speed: 17.6ms preprocess, 259.4ms inference, 0.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 260.2ms\n",
      "Speed: 19.5ms preprocess, 260.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 258.3ms\n",
      "Speed: 17.1ms preprocess, 258.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.5ms\n",
      "Speed: 18.4ms preprocess, 257.5ms inference, 1.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 256.9ms\n",
      "Speed: 18.1ms preprocess, 256.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 254.3ms\n",
      "Speed: 17.7ms preprocess, 254.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 257.3ms\n",
      "Speed: 18.1ms preprocess, 257.3ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 262.8ms\n",
      "Speed: 19.6ms preprocess, 262.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 1 albopictus, 256.3ms\n",
      "Speed: 17.1ms preprocess, 256.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "No detections above threshold for image: 2cac172d-24a4-4ac0-ad12-51e1c45d58c7.jpeg\n",
      "No detections above threshold for image: f6a4a427-9693-4c34-93a8-bc80ba2b2151.jpeg\n",
      "No detections above threshold for image: 8b85b3f2-a80d-4f71-91c0-6eea7631012b.jpeg\n",
      "No detections above threshold for image: 9c9af1d7-5dbf-4bdb-9980-2b7e9becb048.jpeg\n",
      "No detections above threshold for image: d2a7a904-6270-40d8-b203-7da9352f5465.jpeg\n",
      "No detections above threshold for image: a58d07c8-da0a-4c77-a06c-f36302293da4.jpeg\n",
      "No detections above threshold for image: 5ea21a26-4ee0-46c2-8151-a96f4c409f31.jpeg\n",
      "No detections above threshold for image: dd94d87e-d167-403a-b2bc-164e54e220f5.jpeg\n",
      "No detections above threshold for image: 84da1f98-02be-4189-bc6c-b340613e17df.jpeg\n",
      "No detections above threshold for image: 167e2b05-88ed-4f91-b3f1-43bb54cf92bd.jpeg\n",
      "No detections above threshold for image: 84741405-2fd3-4f9a-b327-5bc2f834735f.jpeg\n",
      "No detections above threshold for image: 4e63d8b6-758b-4349-bead-8c21e240d51a.jpeg\n",
      "No detections above threshold for image: 9dc1f00e-135c-4b5f-9614-4dadcc33c597.jpeg\n",
      "No detections above threshold for image: da0226ce-ef8f-4217-bd5d-38955a232eab.jpeg\n",
      "No detections above threshold for image: 063c9e1d-cd3c-4c8b-9feb-75ef44904d59.jpeg\n",
      "No detections above threshold for image: 7327194f-cfbd-4db4-a41f-44a00d870fcf.jpeg\n",
      "No detections above threshold for image: 360213fb-1f44-4d6e-9e71-6a802c7a74b7.jpeg\n",
      "No detections above threshold for image: 62e8aa3a-af90-4de0-a537-4ac8dd4f61e5.jpeg\n",
      "No detections above threshold for image: 616d30cd-63e8-422a-9a61-6676bcc237a5.jpeg\n",
      "No detections above threshold for image: 5fa87402-3206-43ba-b5a1-a78ace91ece9.jpeg\n",
      "No detections above threshold for image: 3a918cb9-770c-4e13-8201-90858c25c7d0.jpeg\n",
      "No detections above threshold for image: 7c5edea9-a8aa-451f-b1a4-e63a7cc4168a.jpeg\n",
      "No detections above threshold for image: 12822b54-bb03-4806-968b-b7ac6fceda48.jpeg\n",
      "No detections above threshold for image: 4633dfdf-2f2c-4834-bd16-ef332a1c5820.jpeg\n",
      "No detections above threshold for image: f8651621-f5d3-4caa-9b39-3e4b28ac8e82.jpeg\n",
      "No detections above threshold for image: c8a84ab5-6414-4519-bc1c-d871e3f94d82.jpeg\n",
      "No detections above threshold for image: 67c4ad50-83d4-4bc6-8b49-9843507b8e42.jpeg\n",
      "No detections above threshold for image: 0870d9f8-aa65-4eb2-be7c-29ddcf056ae8.jpeg\n",
      "No detections above threshold for image: 2804bbd0-add6-4a79-abb8-1edcbda9d338.jpeg\n",
      "No detections above threshold for image: 91f9fe75-4359-4819-87a6-a5c2e5836bea.jpeg\n",
      "No detections above threshold for image: f2fa7c6b-3456-49ea-a5b8-dc2d581155b8.jpeg\n",
      "No detections above threshold for image: abcd1135-de3d-4374-bc38-112b4765fa07.jpeg\n",
      "No detections above threshold for image: 3c700781-b669-40fa-9dc9-20e85e37590f.jpeg\n",
      "No detections above threshold for image: f19f20b8-a542-4555-bd5e-b2de8f0fd2dd.jpeg\n",
      "No detections above threshold for image: 03d6749a-c5b3-45a3-81fa-b9c2f09eb4ba.jpeg\n",
      "No detections above threshold for image: 8c9548e2-5d1c-4454-b515-920d92859acb.jpeg\n",
      "No detections above threshold for image: 2eb9cea6-460d-4abd-866f-9815e36b4fb8.jpeg\n",
      "No detections above threshold for image: 452562b5-5dce-43c3-9ce6-b3b74dde6be9.jpeg\n",
      "No detections above threshold for image: 75674b48-71e3-416b-9454-a4e3c4271d7b.jpeg\n",
      "No detections above threshold for image: 2cea3b1b-5c05-46dc-844e-1e722a0234a6.jpeg\n",
      "No detections above threshold for image: 98b6fce1-0441-41f2-9f15-ead88b530e80.jpeg\n",
      "No detections above threshold for image: 3b4a1715-45fe-4933-8176-144cf59d3c97.jpeg\n",
      "No detections above threshold for image: ff2422f8-5cea-440d-85c9-3fef9ea056ef.jpeg\n",
      "No detections above threshold for image: f995d508-9856-4c9e-9fc4-c2621514d6d3.jpeg\n",
      "No detections above threshold for image: ca1468e3-1337-48b3-b378-135758317454.jpeg\n",
      "No detections above threshold for image: 4287618a-0bc0-4c66-b973-367cf532b648.jpeg\n",
      "No detections above threshold for image: 5ef5a1ab-555b-48b9-ae2c-7cd13738dc2d.jpeg\n",
      "No detections above threshold for image: 16dbbc39-fcb6-498e-963f-d3807fcc3cec.jpeg\n",
      "No detections above threshold for image: b1de96a0-ae1c-49e9-8a1c-ed4d4166f095.jpeg\n",
      "No detections above threshold for image: 92a02501-bc65-4a92-9ff2-c58a5ae4b6b5.jpeg\n",
      "No detections above threshold for image: e7b85d97-bbfd-41ba-8b1c-553bf8106a6b.jpeg\n",
      "No detections above threshold for image: d9597d33-cb2d-49fe-a6ac-3fb5f83af544.jpeg\n",
      "No detections above threshold for image: 3f9877b2-983c-45a2-9784-64a2e2f9607e.jpeg\n",
      "No detections above threshold for image: a595c35c-1b1f-405e-96b0-3642d76a165f.jpeg\n",
      "No detections above threshold for image: cb137729-abc2-4bc0-9af0-54738dbdeae1.jpeg\n",
      "No detections above threshold for image: 19401811-2635-4492-909c-312ae0f62429.jpeg\n",
      "No detections above threshold for image: c93e13f2-780b-4238-9d03-f3138d615cbc.jpeg\n",
      "No detections above threshold for image: 91f0117d-7648-4951-ad9c-86c27db235b0.jpeg\n",
      "No detections above threshold for image: 1b8a232b-60e3-4756-b07f-5c6436f4f3a4.jpeg\n",
      "No detections above threshold for image: 3a3a7aa7-3390-4481-812e-e11455adde48.jpeg\n",
      "No detections above threshold for image: 67393420-fa37-4d8a-a647-a1fabadb8dc5.jpeg\n",
      "No detections above threshold for image: 845672d2-3415-43f4-91c1-ce551eaf898b.jpeg\n",
      "No detections above threshold for image: c1225ecd-bcce-4534-9a60-0b7492d5ac6a.jpeg\n",
      "No detections above threshold for image: 8a5bb3d4-d55c-45bb-b4e7-a691f878c5c0.jpeg\n",
      "No detections above threshold for image: 9e4abca6-1b85-48c0-916b-30e690279124.jpeg\n",
      "No detections above threshold for image: b407fd1a-a6eb-4819-973e-eceee6c5a8c2.jpeg\n",
      "No detections above threshold for image: ef897688-6897-4291-9b41-3c684a3d67ef.jpeg\n",
      "No detections above threshold for image: 32e570b4-161f-407f-9512-a5eff43452d3.jpeg\n",
      "No detections above threshold for image: 63767936-fb44-41a8-90c6-6f96d61312f4.jpeg\n",
      "No detections above threshold for image: 86e7cee3-92ac-40e5-b0dc-457ddf2e795e.jpeg\n",
      "No detections above threshold for image: c25b0aac-bfaa-4138-8afb-ca824f8fcfb6.jpeg\n",
      "No detections above threshold for image: e28a655c-73f5-45cf-8677-97ad2406afce.jpeg\n",
      "No detections above threshold for image: 305ac4a1-c740-4efb-9406-52061c75dcfa.jpeg\n",
      "No detections above threshold for image: 74f0e740-520e-401b-8161-91ff962ebe8f.jpeg\n",
      "No detections above threshold for image: d5918c3c-dcd7-4f5b-a3d0-427d943b3d19.jpeg\n",
      "No detections above threshold for image: d6cd68e8-d6af-4c30-8f17-f41c55f65972.jpeg\n",
      "No detections above threshold for image: d93d5ba8-10c1-4f20-b48d-032ea5f55862.jpeg\n",
      "No detections above threshold for image: 2b858873-91a7-4e7f-8dd3-7f7345a9b04c.jpeg\n",
      "No detections above threshold for image: a8ad1e9a-a1cb-460f-8a03-3a4dea65cd09.jpeg\n",
      "No detections above threshold for image: a84afc41-fb24-4e83-b033-09bf97f1a1e7.jpeg\n",
      "No detections above threshold for image: fc08fd27-0b82-4c62-b7b8-6527db33c381.jpeg\n",
      "No detections above threshold for image: 07c395a6-a476-4d9e-acc4-0fc4640faefe.jpeg\n",
      "No detections above threshold for image: cf8f8316-7129-4c85-b5b5-2fc62406a42a.jpeg\n",
      "No detections above threshold for image: 17b46dcc-17c3-478f-8d80-8fab9dac1a6d.jpeg\n",
      "No detections above threshold for image: fd449c6f-fa26-4797-90b4-f65d4eb5b9d3.jpeg\n",
      "No detections above threshold for image: e4b45fc6-2c07-48b5-a2e2-89a7269a5215.jpeg\n",
      "No detections above threshold for image: 685a45d8-10d7-4a2f-98d5-e14d1ef0baf3.jpeg\n",
      "No detections above threshold for image: 670e619f-ed1a-43d2-b2e4-80d74614b893.jpeg\n",
      "No detections above threshold for image: 6317a279-8147-4846-b518-e1492cd4de7c.jpeg\n",
      "No detections above threshold for image: 5477657a-88d8-47fe-87f5-663ed25f1237.jpeg\n",
      "No detections above threshold for image: 0a9319b8-070b-435a-b3b5-8347ab52c240.jpeg\n",
      "No detections above threshold for image: 7107025c-6096-43bb-917c-17f76c50105e.jpeg\n",
      "No detections above threshold for image: 5cc4d280-1c50-4729-90ae-540af65ec593.jpeg\n",
      "No detections above threshold for image: 07e5213c-e31d-4967-a5a6-7f347457771d.jpeg\n",
      "No detections above threshold for image: feab7021-ab56-4433-824f-bf2436bdd34f.jpeg\n",
      "No detections above threshold for image: b5bf4381-495a-4631-855d-ea0d0032d2c9.jpeg\n",
      "No detections above threshold for image: c2e4b9be-0252-46c1-a077-ee2231f9fad3.jpeg\n",
      "No detections above threshold for image: ddff4816-55b0-472f-9074-5815b3d9ee64.jpeg\n",
      "No detections above threshold for image: e95104ae-58d5-4b7d-a8b1-309fb0635719.jpeg\n",
      "No detections above threshold for image: fad772e4-e81f-4733-b59f-e932ff6183da.jpeg\n",
      "No detections above threshold for image: 7e1fd24d-27cd-4837-88d1-87176af957fd.jpeg\n",
      "No detections above threshold for image: 5b11c1ef-9296-47b0-b7a0-e56ac17c12dc.jpeg\n",
      "No detections above threshold for image: bd91db7b-04f5-4b9d-bd75-ce527c5f287e.jpeg\n",
      "No detections above threshold for image: 6376baab-5111-4233-986b-5001ae688eb7.jpeg\n",
      "No detections above threshold for image: a8bd345f-b06b-4085-af33-077dfe32daed.jpeg\n",
      "No detections above threshold for image: beb40459-7e8c-45cc-91a4-b0946728902f.jpeg\n",
      "No detections above threshold for image: c2eb5470-5965-4700-84a1-41f5ed0db39d.jpeg\n",
      "No detections above threshold for image: a7b2fdb5-e670-46c6-ae2f-efe1ec1917d4.jpeg\n",
      "No detections above threshold for image: 8b15bfdd-ca19-4502-af48-a7ffaef140a5.jpeg\n",
      "No detections above threshold for image: 0f663f9c-0068-4764-9aac-e29a80346527.jpeg\n",
      "No detections above threshold for image: 4e216c54-1daa-4517-91a8-8bf005cc6129.jpeg\n",
      "No detections above threshold for image: 90b8b0d1-4963-4c1b-a038-9fb46904cbe1.jpeg\n",
      "No detections above threshold for image: c611eaf5-1475-44a4-8667-69a645387631.jpeg\n",
      "No detections above threshold for image: 3125c2a0-a875-4530-8f25-3296be3d818e.jpeg\n",
      "No detections above threshold for image: 195960db-ad39-41a8-b708-f1080872ed04.jpeg\n",
      "No detections above threshold for image: cc878b64-bdb3-4b0d-9710-45f748660baf.jpeg\n",
      "No detections above threshold for image: 20b42034-a0e5-4960-b74e-7e5fb8dfff96.jpeg\n",
      "No detections above threshold for image: f64aafcb-e423-4125-85c9-f82d41372e30.jpeg\n",
      "No detections above threshold for image: e69706ed-b7cf-4565-a65e-1b71f095b0fe.jpeg\n",
      "No detections above threshold for image: 8aa3af3a-91a0-4ff9-963d-2d1e0990b352.jpeg\n",
      "No detections above threshold for image: c5d6c7c8-84fe-4e6b-b25a-ba9e13f56e6d.jpeg\n",
      "No detections above threshold for image: a9d3c3fb-5f5e-4e36-a526-2fa1689b04f7.jpeg\n",
      "No detections above threshold for image: 069c0ed4-4f81-40f4-98d0-dfc4553ff656.jpeg\n",
      "No detections above threshold for image: 223f4665-5350-437e-8d0d-13e4b1ad21bc.jpeg\n",
      "No detections above threshold for image: 9ac3772e-4483-4e68-a16b-98757d960d84.jpeg\n",
      "No detections above threshold for image: 11924d04-69fe-469d-8d1c-119bc0f0b94f.jpeg\n",
      "No detections above threshold for image: e99de36d-acec-48de-87e1-3eadb744f36c.jpeg\n",
      "No detections above threshold for image: c5faae5c-cec0-4f68-80bd-4c68f675570a.jpeg\n",
      "No detections above threshold for image: d19595cc-d15a-40c3-b576-120487498911.jpeg\n",
      "No detections above threshold for image: 9ee2a709-6821-49c6-ad5f-a0831f664a6f.jpeg\n",
      "No detections above threshold for image: 2eb12e3c-65f7-4527-bc6d-460c4bee21f0.jpeg\n",
      "No detections above threshold for image: 7daa68bd-928b-4b43-850f-4626f16d2c14.jpeg\n",
      "No detections above threshold for image: 0ab78764-6857-491b-99d1-f4567efd7f32.jpeg\n",
      "No detections above threshold for image: d7f2b0cd-85a3-44cd-99bb-cbe457de96cd.jpeg\n",
      "No detections above threshold for image: a0424cf2-beae-4e47-804a-4609efc4cf79.jpeg\n",
      "No detections above threshold for image: 965d6ab0-4799-4ad1-b21d-bff7a85e67ad.jpeg\n",
      "No detections above threshold for image: c22585ce-da16-417d-8687-6161ddeef034.jpeg\n",
      "No detections above threshold for image: 28964fc0-e568-43ee-9e22-fd6ae7ee7dd9.jpeg\n",
      "No detections above threshold for image: 3fcace3b-254e-4e79-b3af-b578c04db626.jpeg\n",
      "No detections above threshold for image: 56cbfed1-4ad5-449e-ab34-409fc5a916b4.jpeg\n",
      "No detections above threshold for image: 0ec05b33-b16c-4e23-86c1-538bb037efeb.jpeg\n",
      "No detections above threshold for image: 9137483c-d81b-4eca-ab20-3bf545e5855e.jpeg\n",
      "No detections above threshold for image: a909dc81-886e-46b2-a141-8d223b058ab4.jpeg\n",
      "No detections above threshold for image: df0b7b23-4b1d-479a-9387-6980d007e563.jpeg\n",
      "No detections above threshold for image: 87868e36-b097-48e2-ac70-29bc67f0fb8b.jpeg\n",
      "No detections above threshold for image: 6bdb0dca-93dd-40f1-b9ae-9759bc1b5789.jpeg\n",
      "No detections above threshold for image: f35161fd-3278-4a3f-9543-8979dfe80323.jpeg\n",
      "No detections above threshold for image: b1b977df-dd1e-43fd-9e25-0a21e65990ce.jpeg\n",
      "No detections above threshold for image: c997c05b-4e95-4b31-b0a1-3bcfa0606a07.jpeg\n",
      "No detections above threshold for image: 417a6ab9-97ff-4d0a-8631-2bdf1ab1e09e.jpeg\n",
      "No detections above threshold for image: 4386e1f7-6626-49a5-956b-d1ccecc8f988.jpeg\n",
      "No detections above threshold for image: 34708894-ff23-4209-bd6f-bcd29dff5415.jpeg\n",
      "No detections above threshold for image: a1aca7ec-c709-4da9-b976-2be3525245c6.jpeg\n",
      "No detections above threshold for image: 78d112c6-29f3-45bc-80da-ea4680d75ce0.jpeg\n",
      "No detections above threshold for image: 8d3b4000-08c6-4545-93e6-9286818ad91e.jpeg\n",
      "No detections above threshold for image: 15b6fb8d-8149-45be-b495-2bb4069a3aa7.jpeg\n",
      "No detections above threshold for image: d74c2888-2727-4dea-b90e-10e2b6d64a37.jpeg\n",
      "No detections above threshold for image: 18fb9a65-c548-44ba-af86-2f220a1a5512.jpeg\n",
      "No detections above threshold for image: 813c8580-fa53-4a41-8110-9c89f093dcdd.jpeg\n",
      "No detections above threshold for image: 8f40cc2a-65b7-447b-a111-9ca66dbedee7.jpeg\n",
      "No detections above threshold for image: 66d1def1-60ee-475b-bb32-98bf34ddb120.jpeg\n",
      "No detections above threshold for image: 491456e7-d4a4-4c25-9b84-7dbdbe8f2051.jpeg\n",
      "No detections above threshold for image: b354e8d4-7d8f-4479-b4cb-dd4f5b7b5ff1.jpeg\n",
      "No detections above threshold for image: aed58175-1266-4149-a8b3-c20c7161d944.jpeg\n",
      "No detections above threshold for image: 84204b9f-8c10-406d-bdd1-790c4b466521.jpeg\n",
      "No detections above threshold for image: 92aa8844-d059-43ac-b6d6-b92117836443.jpeg\n",
      "No detections above threshold for image: da9dbb82-38f7-4f85-bb9e-633c16801a5d.jpeg\n",
      "No detections above threshold for image: 615ca1d2-e5cd-42df-b2e1-7d8820ead3fe.jpeg\n",
      "No detections above threshold for image: f0cca9d1-06cc-43d5-b5c3-0597b269be14.jpeg\n",
      "No detections above threshold for image: 04741ad4-6e1c-416d-acd4-b352cf18ebda.jpeg\n",
      "No detections above threshold for image: 4b6b63fc-43c3-4428-8f41-2a6ea7eec91a.jpeg\n",
      "No detections above threshold for image: 4803f0e6-7709-4dae-9786-4b3b5ce26396.jpeg\n",
      "No detections above threshold for image: fa1f7f19-3f8a-4171-9540-a0d8e4f678ac.jpeg\n",
      "No detections above threshold for image: be364f29-22cd-4424-9cf3-98eab266245a.jpeg\n",
      "No detections above threshold for image: 92742c4a-c8fd-4e3b-8cfa-60d52f26ba8f.jpeg\n",
      "No detections above threshold for image: a049be38-1760-42f8-9f37-a7d7b8dde450.jpeg\n",
      "No detections above threshold for image: bedca634-f975-4989-8cde-b10adbff48a5.jpeg\n",
      "No detections above threshold for image: bc8de947-ad28-4f6c-98a3-c2c2e302df8c.jpeg\n",
      "No detections above threshold for image: 4b31a9ae-50be-455a-b8fd-e1a7a870850f.jpeg\n",
      "No detections above threshold for image: 9b58be90-9152-45ea-84c9-6d98a817f086.jpeg\n",
      "No detections above threshold for image: 175a68df-ee71-4602-b6f4-7308e9f1f18f.jpeg\n",
      "No detections above threshold for image: cda426f3-4616-40fb-96ea-4f40cd5707d9.jpeg\n",
      "No detections above threshold for image: 9018a4fc-0207-43e0-ad6c-9b8a04374f0a.jpeg\n",
      "No detections above threshold for image: f84c4174-3bfb-42eb-8e52-b5af5c7b561f.jpeg\n",
      "No detections above threshold for image: 74362b37-932d-4b9c-86c9-01e0963a266f.jpeg\n",
      "No detections above threshold for image: 7c1b9f66-7f86-40b7-9e94-d4c822819f7c.jpeg\n",
      "No detections above threshold for image: 221c81b4-db24-4c3d-83ce-1803b3a9d473.jpeg\n",
      "No detections above threshold for image: f3e044bf-572c-4d25-bb7d-2c43d5f519b9.jpeg\n",
      "No detections above threshold for image: 6a2a05a5-d113-4f4d-b543-31a80ff4f3ff.jpeg\n",
      "No detections above threshold for image: 9f486c54-8608-4763-aca8-0dbed7cf84d2.jpeg\n",
      "No detections above threshold for image: 651b0353-c02e-4f01-b129-53214a6b5378.jpeg\n",
      "No detections above threshold for image: 6436c4d0-9bba-4ff0-aff2-3dcace59d39c.jpeg\n",
      "No detections above threshold for image: b468a45d-b1d9-4fcc-bebf-25fca147a9ec.jpeg\n",
      "No detections above threshold for image: a4fabc05-3164-465f-9bd3-1964e9b324e2.jpeg\n",
      "No detections above threshold for image: 3d19622e-bd5f-4d80-b959-c73a2b02595a.jpeg\n",
      "No detections above threshold for image: 3c1c305a-0628-4c6d-990b-ba7fd3d63ee3.jpeg\n",
      "No detections above threshold for image: f16aa44b-5be5-4f2d-b4cc-263ad20cb0b9.jpeg\n",
      "No detections above threshold for image: 4052f632-17c0-4e38-b323-7ee17ff2e2e8.jpeg\n",
      "No detections above threshold for image: 1e908540-19be-438c-b28f-b97f4734ac87.jpeg\n",
      "No detections above threshold for image: 90b40ef2-012d-4880-ad0a-4422f0ce8df1.jpeg\n",
      "No detections above threshold for image: 27d2800b-4eb7-4312-a058-37d227c117aa.jpeg\n",
      "No detections above threshold for image: e159fe8a-2810-4b83-89e6-71504446199b.jpeg\n",
      "No detections above threshold for image: 62aeb0d0-2be6-4c81-a4da-6b7fe7d8ff5c.jpeg\n",
      "No detections above threshold for image: 78a0332d-4ea3-4ac9-aa27-06a9103ef890.jpeg\n",
      "No detections above threshold for image: 9c540f59-9ea8-4478-adb4-a5fe1201e5fb.jpeg\n",
      "No detections above threshold for image: 120dbc2e-d2f2-4e7f-969c-49055306eece.jpeg\n",
      "No detections above threshold for image: a4d04bd0-8096-4c7f-b655-9f7c347d383f.jpeg\n",
      "No detections above threshold for image: cda1baca-3759-43bf-9b63-4992209d94ff.jpeg\n",
      "No detections above threshold for image: 0df08feb-bd58-4288-ba02-c42bb4f9ff2d.jpeg\n",
      "No detections above threshold for image: 1c60737f-ce88-4208-a51a-4f02c3abed0b.jpeg\n",
      "No detections above threshold for image: 5772f2ed-882c-46a2-809a-f144cb0568bf.jpeg\n",
      "No detections above threshold for image: 0e99a3d4-6674-44fe-9505-8009db9dfe8e.jpeg\n",
      "No detections above threshold for image: 7e6625aa-3fd5-49cc-a765-dc88b2688d01.jpeg\n",
      "No detections above threshold for image: a22f7f95-6ef5-4440-bdae-21358100bffe.jpeg\n",
      "No detections above threshold for image: 14270465-8cd2-4e76-9906-9a8aed21bf40.jpeg\n",
      "No detections above threshold for image: 8104f0e7-444b-4875-bed1-64a50f723124.jpeg\n",
      "No detections above threshold for image: 5f6b9da5-95c4-4635-af51-895c2fa32411.jpeg\n",
      "No detections above threshold for image: 55497fb7-1f4c-4514-8d95-d17155be7403.jpeg\n",
      "No detections above threshold for image: 373cb153-8553-44cd-bffb-dc39bdf9adf6.jpeg\n",
      "No detections above threshold for image: b9e42504-5d54-48ff-b2c1-18e43c0666cb.jpeg\n",
      "No detections above threshold for image: 9a46c7a9-5b3a-4fe3-9e0f-f4b5c8cceaf4.jpeg\n",
      "No detections above threshold for image: 03ef458e-8f40-4d42-811b-f3c2db667e12.jpeg\n",
      "No detections above threshold for image: 0031063e-716a-4080-934c-77598dc8de72.jpeg\n",
      "No detections above threshold for image: 344e74b5-f0b3-46cd-a082-97238e2cda5c.jpeg\n",
      "No detections above threshold for image: 7108bc63-6010-4a45-ab07-1a6999ad56d0.jpeg\n",
      "No detections above threshold for image: b0114543-8a81-4dd7-8d71-c6cf0d7604e5.jpeg\n",
      "No detections above threshold for image: a573eb7e-a5cb-479a-8ad4-362df11a7b29.jpeg\n",
      "No detections above threshold for image: fbe9717c-3d69-4529-94ee-f1f4ff48e4b5.jpeg\n",
      "No detections above threshold for image: c258f385-f551-48fb-bcd7-5691b699e33d.jpeg\n",
      "No detections above threshold for image: 23d6a2e2-03f7-4ca7-b998-4c08047a11b1.jpeg\n",
      "No detections above threshold for image: 2b5d0dce-76bd-4a38-9c78-f6f7db5e78e0.jpeg\n",
      "No detections above threshold for image: 460d8d46-2f01-4c0d-8f18-49dadb309388.jpeg\n",
      "No detections above threshold for image: ec26e4aa-96b4-4bf8-ab1b-e9bfe8d5b497.jpeg\n",
      "No detections above threshold for image: 3e4d4fc1-1b46-461b-86cb-abf735ec7257.jpeg\n",
      "No detections above threshold for image: 2a651700-0df3-4295-b223-3e53ccf2cc8f.jpeg\n",
      "No detections above threshold for image: fae311fd-a029-4bc5-ada9-e240a2a2bc8d.jpeg\n",
      "No detections above threshold for image: 5f5d0d1c-5dec-4d66-bbd9-2c69c9cf4eeb.jpeg\n",
      "No detections above threshold for image: 48141de8-db9f-481f-b870-4cf25952b827.jpeg\n",
      "No detections above threshold for image: ccd1ca77-5165-499a-956d-d5555550ddc4.jpeg\n",
      "No detections above threshold for image: 9192c4fd-963b-41e1-9475-1488848fb373.jpeg\n",
      "No detections above threshold for image: 5e20a46c-b98f-4606-b4df-1ba5602c430d.jpeg\n",
      "No detections above threshold for image: 1ac5b5bb-b615-4013-95c8-c39a2c130cf8.jpeg\n",
      "No detections above threshold for image: ac2c9893-212b-4f41-a762-32953835ff8d.jpeg\n",
      "No detections above threshold for image: 4d87f7ed-9433-484f-82cd-106993152b53.jpeg\n",
      "No detections above threshold for image: ed3124f1-4be2-48a6-963d-0e4dfa2bdca1.jpeg\n",
      "No detections above threshold for image: 27a375a7-e809-4587-93f9-68e9762b8509.jpeg\n",
      "No detections above threshold for image: 0ad31287-d62f-4a96-8e21-6d2773797684.jpeg\n",
      "No detections above threshold for image: 34a0c0df-b22b-4f9b-b111-8fc375fad2f5.jpeg\n",
      "No detections above threshold for image: 0f66ea3e-dba5-4424-9ed4-23c5c9419d13.jpeg\n",
      "No detections above threshold for image: c6ae5215-a55b-49ae-b920-f1adc794f21f.jpeg\n",
      "No detections above threshold for image: b7392bd7-20c9-4f6f-8cd4-21af0215d138.jpeg\n",
      "No detections above threshold for image: 84d64b6a-fa7a-47d3-a223-689e04c3295a.jpeg\n",
      "No detections above threshold for image: 02043b0e-3d7d-4ca4-a36f-4bf97c344264.jpeg\n",
      "No detections above threshold for image: 2406e3a6-505e-4674-b4f6-d73f0543e1d5.jpeg\n",
      "No detections above threshold for image: edc597d1-8b44-4fe5-9e07-4f8f59f38a0c.jpeg\n",
      "No detections above threshold for image: 6144b1bd-c016-4f6e-bfdb-c51c43af369e.jpeg\n",
      "No detections above threshold for image: 1ccf5f10-bee6-4047-b750-301b329b04e1.jpeg\n",
      "No detections above threshold for image: f471732b-e86a-4b41-b499-33763a42fb2c.jpeg\n",
      "No detections above threshold for image: 916bebd9-fc40-4a4c-8b5d-a38f54ef3698.jpeg\n",
      "No detections above threshold for image: b4e8060b-265f-41ca-a488-681494494a81.jpeg\n",
      "No detections above threshold for image: 6b2af5fb-e8cc-45d8-8721-a8f8422f34da.jpeg\n",
      "No detections above threshold for image: 4fb111a0-27ed-4ebb-b5a4-3fa47b80bfc9.jpeg\n",
      "No detections above threshold for image: d860ea0a-480e-4ad8-848a-270e8ca17d82.jpeg\n",
      "No detections above threshold for image: 065f03d7-48db-4168-8aa2-7e482c31e3b1.jpeg\n",
      "No detections above threshold for image: ec3c8d12-411e-44ab-98f6-0ea213941bfa.jpeg\n",
      "No detections above threshold for image: 0d7fda56-9014-4d0e-9802-993925febec0.jpeg\n",
      "No detections above threshold for image: 94554e5f-37c2-4512-a9bf-e31ff7c55565.jpeg\n",
      "No detections above threshold for image: f99dd95b-e554-4d3f-a881-1604b2b54ca7.jpeg\n",
      "No detections above threshold for image: 0d35ce5f-d723-41ab-b9e5-9ee8c25593ed.jpeg\n",
      "No detections above threshold for image: 6c53439b-11cd-4145-888f-596b6d716aac.jpeg\n",
      "No detections above threshold for image: 87573bc0-f7fd-4da6-b085-c331d740039f.jpeg\n",
      "No detections above threshold for image: 453404c8-f81c-41e5-a610-3df944658133.jpeg\n",
      "No detections above threshold for image: 65a2a520-97c2-443e-af7f-8f3e982a4f73.jpeg\n",
      "No detections above threshold for image: 79d6c162-db4c-4501-a64e-d1bc2ff27808.jpeg\n",
      "No detections above threshold for image: 32c5ce62-8de1-4ba3-af8e-dc7fe0b7456b.jpeg\n",
      "No detections above threshold for image: 0d068c1a-fc7d-4797-abae-8afc08be660b.jpeg\n",
      "No detections above threshold for image: ca988521-2f2b-4298-9613-f83ad69a0c92.jpeg\n",
      "No detections above threshold for image: 40b987b5-63a9-4e1c-b613-781544bbb23a.jpeg\n",
      "No detections above threshold for image: 296eeeb2-d677-48b6-8cbe-34d15593d680.jpeg\n",
      "No detections above threshold for image: b5164505-a7fb-43c8-bc80-b60c53fa2f1d.jpeg\n",
      "No detections above threshold for image: 30b67cce-8d9b-4032-9054-702236596cd3.jpeg\n",
      "No detections above threshold for image: a0d2c55a-d3c6-473b-a489-f658497f8154.jpeg\n",
      "No detections above threshold for image: 62ca1f73-8df8-4762-8bc6-0fc7ba4bfb9e.jpeg\n",
      "No detections above threshold for image: 7154c57d-6d79-4c11-bb3b-cc8b74ea09df.jpeg\n",
      "No detections above threshold for image: 5c53c448-8738-4094-aeb8-86d5ed33b2cb.jpeg\n",
      "No detections above threshold for image: b45711ca-03c3-44bc-ac20-1bfc0a7511ae.jpeg\n",
      "No detections above threshold for image: 7f2d5948-18c2-480d-a02e-cd54d4dc4f05.jpeg\n",
      "No detections above threshold for image: 27e7ca2e-e27c-44e3-969a-8e593317d6cd.jpeg\n",
      "No detections above threshold for image: 6f69d89b-eba2-410c-83a2-a7f8639976d7.jpeg\n",
      "No detections above threshold for image: f0142330-928e-4fa7-9709-001330db1a54.jpeg\n",
      "No detections above threshold for image: d6a596ab-07a1-4284-88d5-7cc3a08232a1.jpeg\n",
      "No detections above threshold for image: 1728aba6-2d30-4ffb-aa00-ad52091f10e5.jpeg\n",
      "No detections above threshold for image: 90690b80-87de-4711-9a91-3d6ffa672ee4.jpeg\n",
      "No detections above threshold for image: f3b6f69d-aa88-497c-a50f-672e2da7ffd2.jpeg\n",
      "No detections above threshold for image: 00fbfad7-9722-4581-831c-79faa576ea7f.jpeg\n",
      "No detections above threshold for image: 7d3e790a-65a6-4029-8522-8865aa0a0aac.jpeg\n",
      "No detections above threshold for image: af1ebc05-825d-480c-b8e9-d1d28d761a0b.jpeg\n",
      "No detections above threshold for image: ed1bdf6c-31ac-4e75-be11-8ff41bae2423.jpeg\n",
      "No detections above threshold for image: 9d0d18cb-7466-41ca-bc3b-65f447cb4489.jpeg\n",
      "No detections above threshold for image: 83842b2c-7d8a-492a-8dfd-220c5ece1bc3.jpeg\n",
      "No detections above threshold for image: ba22d436-37a8-41e3-ab52-9fd89afae6f5.jpeg\n",
      "No detections above threshold for image: 274d9771-b571-4d6b-9755-b2c7fbe597c0.jpeg\n",
      "No detections above threshold for image: f5017eca-2636-4a51-b57d-db6f94dacb6f.jpeg\n",
      "No detections above threshold for image: ad5aba3e-8ace-49e0-bf14-af2a91ea897f.jpeg\n",
      "No detections above threshold for image: 0e43f1b1-7bae-4ef7-90da-c192a17d1805.jpeg\n",
      "No detections above threshold for image: ec7264d5-9a18-4b1c-a349-be38f37cd666.jpeg\n",
      "No detections above threshold for image: cd63762c-0a6f-4225-8c52-75b420388095.jpeg\n",
      "No detections above threshold for image: 80dc41c3-280a-4e17-b919-1cf4a294b058.jpeg\n",
      "No detections above threshold for image: fcfec73a-49ca-435c-aa3a-bfaa36446e19.jpeg\n",
      "No detections above threshold for image: 7ce8065d-ef25-4008-b156-785157b0ba13.jpeg\n",
      "No detections above threshold for image: 38266f91-a7fb-475b-ae22-e2c6244dd28a.jpeg\n",
      "No detections above threshold for image: 81f374f4-b8b8-4df5-98c7-1e8c41df221d.jpeg\n",
      "No detections above threshold for image: c1db492f-ff9b-4f50-b18e-d89d0b9fbad2.jpeg\n",
      "No detections above threshold for image: 98dfc170-94f8-4536-899a-7f1dce04471f.jpeg\n",
      "No detections above threshold for image: 8d370e31-80a1-493c-b300-8592ae7b47fb.jpeg\n",
      "No detections above threshold for image: 4debb54d-274f-41bc-b2a8-ccf75bbceea5.jpeg\n",
      "No detections above threshold for image: 0365d78b-2064-4d54-b15c-994d1950479a.jpeg\n",
      "No detections above threshold for image: cc534b4e-0cb9-40fa-9aa1-795e2ea77e01.jpeg\n",
      "No detections above threshold for image: c84caf37-ed09-40e2-bf85-6c5f3c3b6668.jpeg\n",
      "No detections above threshold for image: 6a7cb700-2b95-40fb-a36e-1feb6aa274af.jpeg\n",
      "No detections above threshold for image: abf54ff5-fa07-46f0-99be-c3d9cc60fef9.jpeg\n",
      "No detections above threshold for image: bb0986d9-fa04-40a5-8de2-c54045537e17.jpeg\n",
      "No detections above threshold for image: 53a35a8d-2c22-464f-8da5-df7db1116cef.jpeg\n",
      "No detections above threshold for image: b14ca2c0-2528-4487-a163-5de13f59b307.jpeg\n",
      "No detections above threshold for image: 53278c35-1c3a-40dd-91f1-7ef33b32eeb8.jpeg\n",
      "No detections above threshold for image: 1a90d16f-9373-420d-9928-ab632218ae4c.jpeg\n",
      "No detections above threshold for image: fcccf734-a11d-4383-b394-2f23002ae962.jpeg\n",
      "No detections above threshold for image: 44bf3fe6-4102-4135-8082-b2082d53d928.jpeg\n",
      "No detections above threshold for image: 99cad3f7-ad1d-419f-808d-3eb43f2d7d69.jpeg\n",
      "No detections above threshold for image: b165cc46-a654-4452-aa76-1ef4252c164a.jpeg\n",
      "No detections above threshold for image: ccc800cb-835c-4d39-9dd6-535630d0bfd0.jpeg\n",
      "No detections above threshold for image: 6509d5f5-6f52-4427-831d-6818175f90e2.jpeg\n",
      "No detections above threshold for image: e3718f98-7952-42d2-a6b7-230d1ccb631b.jpeg\n",
      "No detections above threshold for image: 988fe925-5890-44b1-97d6-736d8d6fd9b7.jpeg\n",
      "No detections above threshold for image: a98813d4-a142-4fa6-b84f-c24b1f957be2.jpeg\n",
      "No detections above threshold for image: 4cd51aff-5f1c-4b1a-826c-4de004f833a9.jpeg\n",
      "No detections above threshold for image: 6e6928f8-5f78-4eda-ad32-cf497a7fbe70.jpeg\n",
      "No detections above threshold for image: d79ff754-c00b-433d-9108-571d72832d8d.jpeg\n",
      "No detections above threshold for image: 905a7f94-0aeb-43a0-a479-120f48ee85c2.jpeg\n",
      "No detections above threshold for image: 450457f6-745f-4ad1-8110-fab3e7249e96.jpeg\n",
      "No detections above threshold for image: 98a1d744-fd38-48cc-92d7-72b0d43245f7.jpeg\n",
      "No detections above threshold for image: 2d4c6b55-1c38-4334-b2f5-b3e3ef7de422.jpeg\n",
      "No detections above threshold for image: b8749af1-2c85-46e3-a8b1-f5a97775e2b9.jpeg\n",
      "No detections above threshold for image: 91e2f32f-e680-40ba-a2ab-6ed5ae919270.jpeg\n",
      "No detections above threshold for image: a5757ea9-940a-40c1-bf14-f25df4f7fd5c.jpeg\n",
      "No detections above threshold for image: d2cfa22b-b242-4cbd-88e9-0de947cc2899.jpeg\n",
      "No detections above threshold for image: a107d201-1c72-4263-8815-d698c28a8f39.jpeg\n",
      "No detections above threshold for image: d6a66463-38b6-4756-8ea9-dc254ea93c55.jpeg\n",
      "No detections above threshold for image: f6f492ef-ce94-4402-a4fa-27d089e29168.jpeg\n",
      "No detections above threshold for image: f9d49514-a10e-4d40-b45c-f5ac1d8a9511.jpeg\n",
      "No detections above threshold for image: cf8727ca-2df6-4850-b41d-23d7b8ab81a8.jpeg\n",
      "No detections above threshold for image: 416adbc5-427d-4fd1-9beb-507ec140487e.jpeg\n",
      "No detections above threshold for image: cb8843a3-9de8-4b22-a6e0-2c85f1b59285.jpeg\n",
      "No detections above threshold for image: 4ed11a01-ca18-4009-9e8b-4c29c7d9c4d7.jpeg\n",
      "No detections above threshold for image: b2eac592-a1aa-4549-a7a4-a12323b9e50c.jpeg\n",
      "No detections above threshold for image: 83940543-c311-42ae-bff5-b84702a68e03.jpeg\n",
      "No detections above threshold for image: da1f7c2d-214e-4908-86e3-64d7ea842110.jpeg\n",
      "No detections above threshold for image: c9d5e929-70b1-4546-925a-b765e3567328.jpeg\n",
      "No detections above threshold for image: 90231987-8eb4-44e9-94ed-2f7674c5f7a1.jpeg\n",
      "No detections above threshold for image: bd5fd521-9468-4bc4-8de0-f5b56ca61c56.jpeg\n",
      "No detections above threshold for image: 9fbe7765-f3e5-47e4-aafb-7c151b4a883b.jpeg\n",
      "No detections above threshold for image: 32f5ca5e-f4b7-47af-8f23-db5a804ed8ed.jpeg\n",
      "No detections above threshold for image: c1e19357-d49a-4ad4-a706-094d905eca4d.jpeg\n",
      "No detections above threshold for image: 052e0891-1048-478f-89ba-7e8812a62796.jpeg\n",
      "No detections above threshold for image: 3d7179d9-2959-4586-9a2e-5b67b087ff05.jpeg\n",
      "No detections above threshold for image: 1ec71cc4-7da7-49bf-aca8-9ef91d3b786f.jpeg\n",
      "No detections above threshold for image: f6324704-0abe-47df-977e-8bbb574b65e5.jpeg\n",
      "No detections above threshold for image: 71404d0a-642e-492e-b777-06536f63664d.jpeg\n",
      "No detections above threshold for image: 415215a5-04b5-460f-a204-93c418e93754.jpeg\n",
      "No detections above threshold for image: fa7cf812-7521-4cae-987b-510cb002ffaf.jpeg\n",
      "No detections above threshold for image: 6e4c95cc-247e-4f17-9419-e4b19f6842eb.jpeg\n",
      "No detections above threshold for image: d4d6b9ff-1d8e-4f8d-bccb-104af272a62e.jpeg\n",
      "No detections above threshold for image: ae32dfa6-178f-41eb-96ac-ab4b47d0da87.jpeg\n",
      "No detections above threshold for image: bcae8031-582a-48f4-9b2d-e64ceb01f8f8.jpeg\n",
      "No detections above threshold for image: 8294cd5d-27ff-414c-9801-c99bc6f7c7a7.jpeg\n",
      "No detections above threshold for image: 13ed7625-574f-418a-baef-53f3513cf109.jpeg\n",
      "No detections above threshold for image: cdbe94f1-a76b-413b-bf19-157feada99ef.jpeg\n",
      "No detections above threshold for image: ac412026-676e-4bab-8290-ba0d4d50396b.jpeg\n",
      "No detections above threshold for image: c4b01f99-7ba3-4415-b311-b41d503cc51c.jpeg\n",
      "No detections above threshold for image: 0f438ab8-ab3f-4726-9f5c-5c548b4a77e1.jpeg\n",
      "No detections above threshold for image: 8633472f-f178-4a92-8c1f-ba9287c8b9d8.jpeg\n",
      "No detections above threshold for image: 9a9b9059-a121-4f0f-97b9-24e4f82d340a.jpeg\n",
      "No detections above threshold for image: 933578c0-2311-47cc-b64d-515f123bf024.jpeg\n",
      "No detections above threshold for image: f5b8bb3c-9ec5-46f2-872e-ea00ad006899.jpeg\n",
      "No detections above threshold for image: 91271444-27b8-4073-894b-ebbebd60bba5.jpeg\n",
      "No detections above threshold for image: e9421260-554b-4b80-9a55-43e23be1ac31.jpeg\n",
      "No detections above threshold for image: 592ac19b-3055-4944-b0ac-fd35ea1b3f1e.jpeg\n",
      "No detections above threshold for image: 2cf9eafa-e9c8-4c6d-8dec-486f2361d324.jpeg\n",
      "No detections above threshold for image: e81386cc-12e0-4839-a0e1-ee05c15463b2.jpeg\n",
      "No detections above threshold for image: dbc50da2-dfd6-43eb-ae32-75f909080c5e.jpeg\n",
      "No detections above threshold for image: c08c4e26-f1f3-421d-b164-4c0a8fc95bd0.jpeg\n",
      "No detections above threshold for image: a52c8cab-9ec1-486f-ba32-04af99389f39.jpeg\n",
      "No detections above threshold for image: b49e20bf-897b-4f0a-bc62-a6f910cf2bb0.jpeg\n",
      "No detections above threshold for image: 6a083e8b-0928-4f27-a731-fcc392b0b8b7.jpeg\n",
      "No detections above threshold for image: 818eaca8-2ff7-4bc3-a474-4862095d526e.jpeg\n",
      "No detections above threshold for image: 10fcd07a-ec1a-48d6-b4ba-8891347d4232.jpeg\n",
      "Generated submission with 554 predictions\n",
      "Unique images in submission: 525\n",
      "Unique classes predicted: 4\n",
      "\n",
      "Class distribution in predictions:\n",
      "LabelName\n",
      "aegypti       396\n",
      "albopictus    141\n",
      "culex          13\n",
      "culiseta        4\n",
      "Name: count, dtype: int64\n",
      "Best model saved to: outputs/mosquito_yolo/weights/best.pt\n",
      "Submission file generated: submission.csv\n",
      "Ultralytics 8.3.95 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_data/labels/val.cache... 750 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [02:37<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750        750      0.648      0.403      0.378      0.249\n",
      "               aegypti          5          5          1          0     0.0145    0.00912\n",
      "            albopictus        345        345      0.774      0.936      0.895      0.581\n",
      "             anopheles          5          5          1          0      0.015     0.0126\n",
      "                 culex        318        318      0.656      0.928      0.858       0.57\n",
      "              culiseta         48         48      0.319      0.417      0.321      0.201\n",
      "    japonicus/koreicus         29         29      0.138      0.138      0.163      0.119\n",
      "Speed: 1.5ms preprocess, 201.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as tf\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import yaml\n",
    "import albumentations as A\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class Config:\n",
    "    # Data paths\n",
    "    data_dir = \"/kaggle/input/dlp-object-detection-week-10/final_dlp_data/final_dlp_data\"\n",
    "    train_images_dir = os.path.join(data_dir, \"train\", \"images\")\n",
    "    train_labels_dir = os.path.join(data_dir, \"train\", \"labels\")\n",
    "    test_images_dir = os.path.join(data_dir, \"test\", \"images\")\n",
    "    output_dir = \"outputs\"\n",
    "    yolo_data_dir = \"yolo_data\"\n",
    "    \n",
    "    # YOLO model configuration\n",
    "    yolo_model = \"yolov8x.pt\"\n",
    "    yolo_img_size = 1280  # Larger image size for better small object detection\n",
    "    \n",
    "    # Training parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 4  # Reduced due to larger model\n",
    "    epochs = 10    # Increased epochs\n",
    "    val_split = 0.1\n",
    "    \n",
    "    # Learning rate configuration\n",
    "    lr0 = 0.01      # Initial learning rate\n",
    "    lrf = 0.01      # Final learning rate as a fraction of initial\n",
    "    momentum = 0.937\n",
    "    weight_decay = 0.0005\n",
    "    \n",
    "    # Inference parameters\n",
    "    confidence_threshold = 0.25\n",
    "    iou_threshold = 0.45    # For NMS\n",
    "    \n",
    "    # Class mapping\n",
    "    class_names = {\n",
    "        0: \"aegypti\",\n",
    "        1: \"albopictus\",\n",
    "        2: \"anopheles\",\n",
    "        3: \"culex\",\n",
    "        4: \"culiseta\",\n",
    "        5: \"japonicus/koreicus\"\n",
    "    }\n",
    "    \n",
    "    class_ids = {name: idx for idx, name in class_names.items()}\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "os.makedirs(Config.output_dir, exist_ok=True)\n",
    "os.makedirs(Config.yolo_data_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(Config.yolo_data_dir, \"images\", \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(Config.yolo_data_dir, \"images\", \"val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(Config.yolo_data_dir, \"labels\", \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(Config.yolo_data_dir, \"labels\", \"val\"), exist_ok=True)\n",
    "\n",
    "def prepare_yolo_dataset():\n",
    "    \"\"\"Prepare dataset in YOLOv8 format\"\"\"\n",
    "    print(\"Preparing YOLO dataset structure...\")\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(Config.train_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Split train/val\n",
    "    train_files, val_files = train_test_split(\n",
    "        image_files, test_size=Config.val_split, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"Training images: {len(train_files)}, Validation images: {len(val_files)}\")\n",
    "    \n",
    "    # Copy files to YOLO structure\n",
    "    for img_file in train_files:\n",
    "        # Copy image\n",
    "        shutil.copy(\n",
    "            os.path.join(Config.train_images_dir, img_file),\n",
    "            os.path.join(Config.yolo_data_dir, \"images\", \"train\", img_file)\n",
    "        )\n",
    "        \n",
    "        # Copy label if exists\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        if os.path.exists(os.path.join(Config.train_labels_dir, label_file)):\n",
    "            shutil.copy(\n",
    "                os.path.join(Config.train_labels_dir, label_file),\n",
    "                os.path.join(Config.yolo_data_dir, \"labels\", \"train\", label_file)\n",
    "            )\n",
    "    \n",
    "    for img_file in val_files:\n",
    "        # Copy image\n",
    "        shutil.copy(\n",
    "            os.path.join(Config.train_images_dir, img_file),\n",
    "            os.path.join(Config.yolo_data_dir, \"images\", \"val\", img_file)\n",
    "        )\n",
    "        \n",
    "        # Copy label if exists\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        if os.path.exists(os.path.join(Config.train_labels_dir, label_file)):\n",
    "            shutil.copy(\n",
    "                os.path.join(Config.train_labels_dir, label_file),\n",
    "                os.path.join(Config.yolo_data_dir, \"labels\", \"val\", label_file)\n",
    "            )\n",
    "    \n",
    "    # Create YAML config file for YOLO\n",
    "    yaml_content = {\n",
    "        'path': os.path.abspath(Config.yolo_data_dir),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'names': Config.class_names\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(Config.yolo_data_dir, 'data.yaml'), 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    \n",
    "    return os.path.join(Config.yolo_data_dir, 'data.yaml')\n",
    "\n",
    "class MosquitoTestDataset(Dataset):\n",
    "    def __init__(self, images_dir, transforms=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transforms = transforms\n",
    "        self.img_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.img_files[idx])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        original_height, original_width = img.shape[:2]\n",
    "        img_id = self.img_files[idx]\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        img_tensor = tf.to_tensor(img)\n",
    "        \n",
    "        return img_tensor, img_id, (original_height, original_width)\n",
    "\n",
    "\n",
    "def get_test_transforms():\n",
    "    \"\"\"Get test-time augmentations using Albumentations\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height=Config.yolo_img_size, width=Config.yolo_img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "def yolo_to_submission_format(results, image_ids, original_dims):\n",
    "    \"\"\"Convert YOLO detection results to submission format\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i, (result, img_id, dims) in enumerate(zip(results, image_ids, original_dims)):\n",
    "        original_height, original_width = dims\n",
    "        \n",
    "        # If detections exist\n",
    "        if len(result.boxes) > 0:\n",
    "            boxes = result.boxes.xyxyn.cpu().numpy()  # normalized xmin, ymin, xmax, ymax\n",
    "            scores = result.boxes.conf.cpu().numpy()\n",
    "            class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # Filter by confidence threshold\n",
    "            mask = scores >= Config.confidence_threshold\n",
    "            boxes = boxes[mask]\n",
    "            scores = scores[mask]\n",
    "            class_ids = class_ids[mask]\n",
    "            \n",
    "            # Process each detection\n",
    "            for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "                x1, y1, x2, y2 = box\n",
    "                \n",
    "                # Convert from xyxy to YOLO format (center, width, height)\n",
    "                x_center = (x1 + x2) / 2\n",
    "                y_center = (y1 + y2) / 2\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                \n",
    "                class_name = Config.class_names.get(class_id, \"Unknown\")\n",
    "                \n",
    "                predictions.append({\n",
    "                    'ImageID': img_id,\n",
    "                    'LabelName': class_name,\n",
    "                    'Conf': float(score),\n",
    "                    'xcenter': float(x_center),\n",
    "                    'ycenter': float(y_center),\n",
    "                    'bbx_width': float(width),\n",
    "                    'bbx_height': float(height)\n",
    "                })\n",
    "        else:\n",
    "            # If no detections found, add a default prediction\n",
    "            # This is a fallback to ensure every image has at least one prediction\n",
    "            most_common_class = \"aegypti\"\n",
    "            \n",
    "            print(f\"No detections above threshold for image: {img_id}\")\n",
    "            \n",
    "            predictions.append({\n",
    "                'ImageID': img_id,\n",
    "                'LabelName': most_common_class,\n",
    "                'Conf': float(Config.confidence_threshold),\n",
    "                'xcenter': 0.5,\n",
    "                'ycenter': 0.5,\n",
    "                'bbx_width': 0.3,\n",
    "                'bbx_height': 0.3\n",
    "            })\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def visualize_yolo_predictions(model, val_dir, num_images=5):\n",
    "    \"\"\"Visualize YOLO model predictions\"\"\"\n",
    "    val_images = [os.path.join(val_dir, f) for f in os.listdir(val_dir) \n",
    "                  if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if len(val_images) == 0:\n",
    "        print(\"No validation images found.\")\n",
    "        return\n",
    "    \n",
    "    sample_images = random.sample(val_images, min(num_images, len(val_images)))\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        # Perform prediction\n",
    "        results = model.predict(img_path, conf=Config.confidence_threshold)\n",
    "        \n",
    "        # Plot results\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        result_plotted = results[0].plot()\n",
    "        plt.imshow(cv2.cvtColor(result_plotted, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Detection {i+1}\")\n",
    "        plt.savefig(os.path.join(Config.output_dir, f'yolo_prediction_{i+1}.png'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def generate_yolo_predictions(model, test_dataset):\n",
    "    \"\"\"Generate predictions for test dataset using YOLOv8 model\"\"\"\n",
    "    image_ids = []\n",
    "    original_dims = []\n",
    "    results = []\n",
    "    \n",
    "    for img_tensor, img_id, dims in tqdm(test_dataset, desc=\"Generating test predictions\"):\n",
    "        # Convert tensor to numpy and prepare for YOLO\n",
    "        img_np = img_tensor.permute(1, 2, 0).numpy() * 255\n",
    "        img_np = img_np.astype(np.uint8)\n",
    "        \n",
    "        # Run inference\n",
    "        result = model.predict(img_np, conf=Config.confidence_threshold, iou=Config.iou_threshold)[0]\n",
    "        \n",
    "        # Store results\n",
    "        results.append(result)\n",
    "        image_ids.append(img_id)\n",
    "        original_dims.append(dims)\n",
    "    \n",
    "    # Convert to submission format\n",
    "    predictions = yolo_to_submission_format(results, image_ids, original_dims)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame(predictions)\n",
    "    submission_df.insert(0, 'id', range(len(submission_df)))\n",
    "    \n",
    "    # Save submission file\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(f\"Generated submission with {len(predictions)} predictions\")\n",
    "    print(f\"Unique images in submission: {submission_df['ImageID'].nunique()}\")\n",
    "    print(f\"Unique classes predicted: {submission_df['LabelName'].nunique()}\")\n",
    "    \n",
    "    # Display counts of each class\n",
    "    class_counts = submission_df['LabelName'].value_counts()\n",
    "    print(\"\\nClass distribution in predictions:\")\n",
    "    print(class_counts)\n",
    "\n",
    "def train_yolo_model(data_yaml_path):\n",
    "    \"\"\"Train a YOLOv8 model with custom hyperparameters\"\"\"\n",
    "    print(f\"Training YOLOv8 model using {Config.yolo_model} as base...\")\n",
    "    \n",
    "    # Load YOLOv8 model \n",
    "    model = YOLO(Config.yolo_model)\n",
    "    \n",
    "    # Train with custom hyperparameters\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=Config.epochs,\n",
    "        imgsz=Config.yolo_img_size,\n",
    "        batch=Config.batch_size,\n",
    "        workers=4,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu',\n",
    "        project=Config.output_dir,\n",
    "        name='mosquito_yolo',\n",
    "        pretrained=True,\n",
    "        optimizer='SGD',  # SGD with momentum\n",
    "        lr0=Config.lr0,\n",
    "        lrf=Config.lrf,\n",
    "        momentum=Config.momentum,\n",
    "        weight_decay=Config.weight_decay,\n",
    "        warmup_epochs=3,\n",
    "        warmup_momentum=0.8,\n",
    "        warmup_bias_lr=0.1,\n",
    "        box=7.5,   # box loss gain\n",
    "        cls=0.5,   # cls loss gain\n",
    "        hsv_h=0.015,  # hue augmentation\n",
    "        hsv_s=0.7,    # saturation augmentation \n",
    "        hsv_v=0.4,    # value augmentation\n",
    "        degrees=10,   # rotation augmentation\n",
    "        translate=0.1,  # translation augmentation\n",
    "        scale=0.5,     # scale augmentation\n",
    "        fliplr=0.5,    # horizontal flip\n",
    "        flipud=0.1,    # vertical flip (less common for this task)\n",
    "        mosaic=1.0,    # mosaic augmentation\n",
    "        mixup=0.1,     # mixup augmentation (good for small objects)\n",
    "        copy_paste=0.1,  # copy-paste augmentation\n",
    "        auto_augment='randaugment',  # use random augmentation\n",
    "        cache=True,    # cache images for faster training\n",
    "        rect=False,    # rectangular training\n",
    "        cos_lr=True,   # cosine LR scheduler\n",
    "        close_mosaic=10,  # close mosaic augmentation last 10 epochs\n",
    "        amp=True       # mixed precision training\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Using device: {Config.device}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    \n",
    "    # Prepare data in YOLO format\n",
    "    data_yaml_path = prepare_yolo_dataset()\n",
    "    \n",
    "    # Train YOLO model\n",
    "    results = train_yolo_model(data_yaml_path)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = YOLO(os.path.join(Config.output_dir, 'mosquito_yolo', 'weights', 'best.pt'))\n",
    "    \n",
    "    # Visualize predictions on validation set\n",
    "    print(\"Visualizing model predictions...\")\n",
    "    visualize_yolo_predictions(\n",
    "        best_model, \n",
    "        os.path.join(Config.yolo_data_dir, \"images\", \"val\")\n",
    "    )\n",
    "    \n",
    "    # Prepare test dataset\n",
    "    test_transforms = get_test_transforms()\n",
    "    test_dataset = MosquitoTestDataset(Config.test_images_dir, transforms=test_transforms)\n",
    "    \n",
    "    # Generate predictions for test set\n",
    "    print(\"Generating predictions for test set...\")\n",
    "    generate_yolo_predictions(best_model, test_dataset)\n",
    "    \n",
    "    print(\"Best model saved to:\", os.path.join(Config.output_dir, 'mosquito_yolo', 'weights', 'best.pt'))\n",
    "    print(\"Submission file generated: submission.csv\")\n",
    "    \n",
    "    # Additional analysis of the model's performance\n",
    "    best_model.val(data=data_yaml_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11404671,
     "sourceId": 96038,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25001.262247,
   "end_time": "2025-03-24T15:08:09.064459",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-24T08:11:27.802212",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "19cfb503b6484735baf150380b23fbbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bda1da4e7924ed29eebd2fc0127afbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32ff1f361d504835be04d7020418504d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a408ba3d33834fd5b5f865881ce40c68",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_4a9c7bb204744e56b4554fd8cfbfb171",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡525/525â€‡[03:22&lt;00:00,â€‡â€‡2.51it/s]"
      }
     },
     "4a9c7bb204744e56b4554fd8cfbfb171": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5045c38cec4a41949e704e8e31df4c82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "550fa9b3b05441599aa5bb376f63b28e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_19cfb503b6484735baf150380b23fbbb",
       "max": 525.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8d531bee6e184a54bf5815b694d8eb09",
       "tabbable": null,
       "tooltip": null,
       "value": 525.0
      }
     },
     "8d531bee6e184a54bf5815b694d8eb09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "997b5bcdfc144612857b0a90d379f160": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf6deec194a84e0da236048dbd26361d",
        "IPY_MODEL_550fa9b3b05441599aa5bb376f63b28e",
        "IPY_MODEL_32ff1f361d504835be04d7020418504d"
       ],
       "layout": "IPY_MODEL_2bda1da4e7924ed29eebd2fc0127afbe",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a408ba3d33834fd5b5f865881ce40c68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf6deec194a84e0da236048dbd26361d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca11d40f4b4d432c930b727b1e6fc7b2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5045c38cec4a41949e704e8e31df4c82",
       "tabbable": null,
       "tooltip": null,
       "value": "Generatingâ€‡testâ€‡predictions:â€‡100%"
      }
     },
     "ca11d40f4b4d432c930b727b1e6fc7b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
